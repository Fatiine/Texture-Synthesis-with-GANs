{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spatial GAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mALB6nudjfmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pdb\n",
        "import pickle\n",
        "import copy\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3V3zxg7jh73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SGAN():\n",
        "    def __init__(self, sess):\n",
        "      self.sess = sess\n",
        "      \n",
        "      self.batch_size = 32\n",
        "      self.image_rows = 28\n",
        "      self.image_cols = 28\n",
        "      \n",
        "      #Spatial size of the random noise\n",
        "      self.z_size = 9\n",
        "      # Dimensionality of each vector \n",
        "      self.z_dim = 100\n",
        "      \n",
        "      self.channels = 3\n",
        "      # dimensionality of the input tensor for the discriminator netword \n",
        "      self.image_shape = (self.image_rows, self.image_cols, self.channels)\n",
        "      # dimensionality of the input tensor for the generator network\n",
        "      self.z_dim = (self.z_size, self.z_size, self_z_dim)\n",
        "      \n",
        "      self.nbr_layers = 5\n",
        "      \n",
        "      # Discriminators layers and filters \n",
        "      self.disc_filters = [64, 128, 256, 512, 1]\n",
        "      self.disc_layers = []\n",
        "      self.disc_bn_layers = []  # Batch normalization layers \n",
        "      self.disc_weights = []\n",
        "      \n",
        "      # Generator layers and filters \n",
        "      self.gen_filters = [3, 64, 128, 256, 512]\n",
        "      self.gen_layers = []\n",
        "      self.gen_bn_layers = []  # Batch normalization layers \n",
        "      self.gen_weights = []\n",
        "      \n",
        "      # We applied batch normalization on all layers,\n",
        "      # except the output layer of G, \n",
        "      # the input and output layers of D\n",
        "      \n",
        "      for i in range(0, self.nbr_layers - 1):\n",
        "        self.gen_bn_layers.append(BatchNormalization(epsilon=1e-5, momentum=0.9, name=\"batch_norm\"+str(i+1)))\n",
        "      \n",
        "      for i in range(0, self.nbr_layers - 2):\n",
        "        self.disc_bn_layers.append(BatchNormalization(epsilon=1e-5, momentum=0.9, name=\"batch_norm\"+str(i+1)))\n",
        "        \n",
        "    def build_generator(self, z, train=True):\n",
        "      shape = tf.shape(z)\n",
        "      l = tf.cast(shape[1], tf.int32)\n",
        "      m = tf.cast(shape[2], tf.int32)\n",
        "      \n",
        "      self.gen_layers.append(z)\n",
        "      \n",
        "      for i in range(self.nbr_layers - 1):\n",
        "        h = (2**(i+1))*l\n",
        "        w = (2**(i+1))*m\n",
        "        output_shape = (self.batch_size, h, w, self.gen_filters[i])\n",
        "        \n",
        "        shape = (kernel_size, kernel_size, output_shape[-1], self.gen_layers[-1].get_shape()[-1] )\n",
        "        weight = tf.get_variable('W_'+str(suffix), shape, initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "        conv = Conv2DTranspose(128, kernel_size=5, strides=(1/2,1/2), padding=\"same\")(self.gen_layers[-1])\n",
        "        \n",
        "        self.gen_weights.append(weight)\n",
        "        layer = Activation('relu')(self.gen_bn_layers[i])\n",
        "        self.gen_layers.append(layer)\n",
        "      \n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMzRI1k9npD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}