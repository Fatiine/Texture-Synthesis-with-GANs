{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workingfatine_water_sgan_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FHffsU9Qrs-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D, MaxPooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.backend.tensorflow_backend import set_session\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1ZL-FDtx67z",
        "colab_type": "code",
        "outputId": "e4fd31a3-e3b2-4174-d448-e471c7f2a8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "py4crw0errbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GAN():\n",
        "    def __init__(self,dataset_name='',load_model_name=''):\n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        \n",
        "        if (load_model_name == ''):\n",
        "            #X_train = self.load_gan_data(dataset_name)\n",
        "            \n",
        "            #print(\"Loading dataset...\")\n",
        "            \n",
        "            ndata = 200\n",
        "            patch_size = 128\n",
        "            self.patch_size = patch_size\n",
        "            \n",
        "            self.X_tr = np.zeros((ndata, patch_size, patch_size, 3))\n",
        "            \n",
        "            for i in range(ndata):\n",
        "              #if(i%10==0):\n",
        "                #print(\"Image \",i+1)\n",
        "              im = Image.open(\"drive/My Drive/texture/patchset1/patchno\"+str(i)+\".jpg\")\n",
        "              self.X_tr[i,:,:,:] = np.array(im)/255\n",
        "            \n",
        "            print(\"Dataset loaded.\")\n",
        "            \n",
        "            # default parameters for mnist \n",
        "            self.img_rows = self.X_tr.shape[1]\n",
        "            self.img_cols = self.X_tr.shape[2]\n",
        "            self.img_channels = self.X_tr.shape[3]\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "            self.z_width = 4\n",
        "            self.z_height = 4\n",
        "            self.z_depth = 16\n",
        "            self.batch_size = 16\n",
        "            self.iter_count = 0\n",
        "            self.dataset_name = dataset_name\n",
        "            self.model_file = 'models/'+self.dataset_name+'_gan_model.pickle'#\n",
        "\n",
        "            # Build and compile the discriminator and discriminator loss\n",
        "            self.discriminator = self.build_discriminator()\n",
        "            # set discriminator loss\n",
        "            # BEGIN INSERT CODE\n",
        "            self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "            # END INSERT CODE\n",
        "\n",
        "            # Build the generator\n",
        "            self.generator = self.build_generator()\n",
        "\n",
        "        else:\n",
        "            #load gan class and models (generator, discriminator and stacked model)\n",
        "            self.load_gan_model(load_model_name)\n",
        "\n",
        "        # Create the stacked model\n",
        "        #first, create the random vector z in the latent space\n",
        "        z = Input(shape=(self.z_depth,self.z_depth,self.z_depth))\n",
        "        #z = Input(shape=(self.z_dim,))\n",
        "        #create generated (fake) image\n",
        "        img = self.generator(z)\n",
        "\n",
        "        #indicate that for the stacked model, the weights are not trained\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and gives a probability of whether it is a true or\n",
        "        #false image\n",
        "        print(\"img : \", img.shape)\n",
        "        p_true = self.discriminator(img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # In this model, we train the generator only\n",
        "        self.stacked_gen_disc = Model(z, p_true)\n",
        "\n",
        "        # loss\n",
        "        # START INSERT CODE HERE\n",
        "        generator_loss = K.mean(K.log(1 - p_true))\n",
        "        # END INSERT CODE HERE\n",
        "        self.stacked_gen_disc.add_loss(generator_loss)\n",
        "        self.stacked_gen_disc.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(3, kernel_size=5, input_shape=(self.z_depth,self.z_depth,self.z_depth), padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.9))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(self.img_channels, kernel_size=3, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        #model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.z_depth,self.z_depth,self.z_depth))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Conv2D(64, kernel_size=5, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        #model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        #model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.9))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        #model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(256, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.9))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        #model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(512, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.9))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        #model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(1, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        model.add(Activation('sigmoid'))\n",
        "\n",
        "        #model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def load_gan_data(self,dataset_name):\n",
        "        # Load the dataset\n",
        "        if(dataset_name == 'mnist'):\n",
        "            (X_train, _), (_, _) = mnist.load_data()\n",
        "        elif(dataset_name == 'cifar'):\n",
        "            from keras.datasets import cifar10\n",
        "            (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "        else:\n",
        "            print('Error, unknown database')\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        #add a channel dimension, if need be (for mnist data)\n",
        "        if(X_train.ndim ==3):\n",
        "            X_train = np.expand_dims(X_train, axis=3)\n",
        "        return X_train\n",
        "\n",
        "    def save_gan_model(self, model_file):\n",
        "\n",
        "        #save the GAN class instance\n",
        "        gan_temp = GAN(self.dataset_name,'')\n",
        "        gan_temp.generator = self.generator\n",
        "        gan_temp.discriminator = self.discriminator\n",
        "        gan_temp.stacked_gen_disc = []\n",
        "        gan_temp.iter_count = self.iter_count\n",
        "        with open(model_file,'wb') as file_class:\n",
        "            pickle.dump(gan_temp,file_class,-1)\n",
        "\n",
        "    def load_gan_model(self, model_file):\n",
        "\n",
        "        #load GAN class instance\n",
        "        gan_temp = pickle.load(open(model_file,\"rb\",-1))\n",
        "        #copy parameters\n",
        "        self.img_rows = gan_temp.img_rows \n",
        "        self.img_cols = gan_temp.img_cols \n",
        "        self.img_channels = gan_temp.img_channels \n",
        "        self.img_shape = gan_temp.img_shape\n",
        "        self.z_dim = gan_temp.z_dim\n",
        "        self.iter_count = gan_temp.iter_count\n",
        "        self.model_file = gan_temp.model_file\n",
        "        self.dataset_name = gan_temp.dataset_name\n",
        "\n",
        "        #copy models\n",
        "        self.generator = gan_temp.generator\n",
        "        self.discriminator = gan_temp.discriminator\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "        \n",
        "        k=1    #number of internal loops\n",
        "\n",
        "        #load dataset\n",
        "        X_train = self.X_tr\n",
        "        # Adversarial ground truths\n",
        "        d_output_true = np.ones((batch_size, self.z_width, self.z_height, 1))-0.3*np.random.rand(batch_size, self.z_width, self.z_height, 1)\n",
        "        d_output_false = np.zeros((batch_size, self.z_width, self.z_height, 1))+0.25*np.random.rand(batch_size, self.z_width, self.z_height, 1)\n",
        "        d_output_true2 = np.ones((batch_size, self.z_width, self.z_height, 1))\n",
        "        d_output_false2 = np.zeros((batch_size, self.z_width, self.z_height, 1))\n",
        "\n",
        "        first_iter =self.iter_count\n",
        "\n",
        "        for epoch in range(first_iter,epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Train the discriminator\n",
        "            for i in range(0,k):\n",
        "                # Select a random batch of images\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "\n",
        "                z_random = np.random.normal(0, 1, (batch_size, self.z_depth, self.z_depth, self.z_depth))\n",
        "\n",
        "                # Generate a batch of new (fake) images\n",
        "                gen_imgs = self.generator.predict(z_random)\n",
        "                \n",
        "                # START INSERT CODE\n",
        "                d_loss_real = self.discriminator.train_on_batch(imgs, d_output_true)\n",
        "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, d_output_false)\n",
        "                d_loss_real2 = np.mean(self.discriminator.predict(imgs))\n",
        "                d_loss_fake2 = 1-np.mean(self.discriminator.predict(gen_imgs))\n",
        "                # END INSERT CODE\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                d_loss2 = 0.5*(d_loss_real2 + d_loss_fake2)\n",
        "\n",
        "        \n",
        "            \n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random batch of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            z_random = np.random.normal(0, 1, (batch_size, self.z_depth, self.z_depth,self.z_depth))\n",
        "\n",
        "            # Generate a batch of new (fake) images\n",
        "            gen_imgs = self.generator.predict(z_random)\n",
        "            # Generator training : try to make generated images be classified as true by the discriminator\n",
        "            g_loss = self.stacked_gen_disc.train_on_batch(z_random,None)\n",
        "\n",
        "            # increase epoch counter\n",
        "            self.iter_count = self.iter_count+1\n",
        "            # Plot the losses\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss2, g_loss))\n",
        "\n",
        "            # Save some random generated images and the models at every sample_interval iterations\n",
        "            if (epoch % 10 == 0):\n",
        "                self.sample_images('images/'+self.dataset_name+'_sample_%06d.png' % epoch)\n",
        "                #self.save_gan_model(self.model_file)\n",
        "\n",
        "    def sample_images(self, image_filename, rand_seed=30):\n",
        "        np.random.seed(rand_seed)\n",
        "\n",
        "        r, c = 2, 2\n",
        "        z_random = np.random.normal(0, 1, (r * c, self.z_depth, self.z_depth, self.z_depth))\n",
        "        gen_imgs = self.generator.predict(z_random)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                #black and white images\n",
        "                if(gen_imgs.shape[3] == 1):\n",
        "                    axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                elif(gen_imgs.shape[3] == 3):   #colour images\n",
        "                    axs[i,j].imshow(gen_imgs[cnt, :,:], vmin=0, vmax=1)\n",
        "                else:\n",
        "                    print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n",
        "                            I can''t handle this data. You''ve made me very sad ...')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(image_filename)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQHAcAS-r3Fq",
        "colab_type": "code",
        "outputId": "fed9284b-9d1f-487f-a88a-f8665cf022b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3672
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    #create the output image and model directories\n",
        "    if (os.path.isdir('images')==0):\n",
        "        os.mkdir('images')\n",
        "    if (os.path.isdir('models')==0):\n",
        "        os.mkdir('models')\n",
        "\n",
        "    #choose dataset\n",
        "    dataset_name = 'mnist'#\n",
        "\n",
        "    #create GAN model\n",
        "    set_session(session)\n",
        "\n",
        "    #create GAN model\n",
        "    model_file = '_gan_model.pickle'\n",
        "    gan = GAN()#,\n",
        "    is_training = 1\n",
        "\n",
        "    if (is_training ==1):\n",
        "        gan.train(epochs=100, batch_size=32, sample_interval=64)\n",
        "    else:\n",
        "        gan.sample_images('images/test_images.png')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.946702, acc.: 50.37%] [G loss: -0.635409]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "1 [D loss: 0.794715, acc.: 50.85%] [G loss: -0.180114]\n",
            "2 [D loss: 0.591364, acc.: 52.40%] [G loss: -0.132091]\n",
            "3 [D loss: 0.590899, acc.: 50.53%] [G loss: -0.150732]\n",
            "4 [D loss: 0.550818, acc.: 52.35%] [G loss: -0.195277]\n",
            "5 [D loss: 0.507792, acc.: 51.40%] [G loss: -0.132570]\n",
            "6 [D loss: 0.451640, acc.: 50.87%] [G loss: -0.159070]\n",
            "7 [D loss: 0.452132, acc.: 50.56%] [G loss: -0.160745]\n",
            "8 [D loss: 0.433737, acc.: 50.97%] [G loss: -0.212941]\n",
            "9 [D loss: 0.438653, acc.: 50.12%] [G loss: -0.166559]\n",
            "10 [D loss: 0.427764, acc.: 50.75%] [G loss: -0.222806]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "11 [D loss: 0.432653, acc.: 50.15%] [G loss: -0.179186]\n",
            "12 [D loss: 0.435689, acc.: 50.10%] [G loss: -0.143552]\n",
            "13 [D loss: 0.442650, acc.: 50.63%] [G loss: -0.142919]\n",
            "14 [D loss: 0.436997, acc.: 50.20%] [G loss: -0.142929]\n",
            "15 [D loss: 0.417308, acc.: 50.67%] [G loss: -0.162583]\n",
            "16 [D loss: 0.414491, acc.: 50.26%] [G loss: -0.157550]\n",
            "17 [D loss: 0.416206, acc.: 50.70%] [G loss: -0.177135]\n",
            "18 [D loss: 0.422318, acc.: 49.81%] [G loss: -0.268188]\n",
            "19 [D loss: 0.484979, acc.: 50.53%] [G loss: -0.034418]\n",
            "20 [D loss: 0.673770, acc.: 50.49%] [G loss: -0.141063]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "21 [D loss: 0.602144, acc.: 49.98%] [G loss: -0.207143]\n",
            "22 [D loss: 0.511946, acc.: 49.60%] [G loss: -0.087479]\n",
            "23 [D loss: 0.877737, acc.: 51.61%] [G loss: -0.130762]\n",
            "24 [D loss: 0.643441, acc.: 48.36%] [G loss: -0.455116]\n",
            "25 [D loss: 0.554062, acc.: 50.80%] [G loss: -0.070402]\n",
            "26 [D loss: 1.287880, acc.: 50.38%] [G loss: -0.080474]\n",
            "27 [D loss: 0.618870, acc.: 52.09%] [G loss: -0.136848]\n",
            "28 [D loss: 0.460445, acc.: 49.49%] [G loss: -0.294242]\n",
            "29 [D loss: 0.455889, acc.: 50.43%] [G loss: -0.154713]\n",
            "30 [D loss: 0.423161, acc.: 50.58%] [G loss: -0.130981]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "31 [D loss: 0.422432, acc.: 50.57%] [G loss: -0.145756]\n",
            "32 [D loss: 0.419088, acc.: 50.70%] [G loss: -0.157179]\n",
            "33 [D loss: 0.421013, acc.: 50.95%] [G loss: -0.151080]\n",
            "34 [D loss: 0.415111, acc.: 51.47%] [G loss: -0.110550]\n",
            "35 [D loss: 0.416587, acc.: 51.53%] [G loss: -0.145874]\n",
            "36 [D loss: 0.419741, acc.: 51.18%] [G loss: -0.237235]\n",
            "37 [D loss: 0.445022, acc.: 52.15%] [G loss: -0.067075]\n",
            "38 [D loss: 0.485050, acc.: 51.81%] [G loss: -0.312775]\n",
            "39 [D loss: 0.439908, acc.: 51.20%] [G loss: -0.261808]\n",
            "40 [D loss: 0.432144, acc.: 51.86%] [G loss: -0.112071]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "41 [D loss: 0.439468, acc.: 51.88%] [G loss: -0.245542]\n",
            "42 [D loss: 0.417892, acc.: 51.99%] [G loss: -0.183921]\n",
            "43 [D loss: 0.418850, acc.: 52.60%] [G loss: -0.239079]\n",
            "44 [D loss: 0.421841, acc.: 53.55%] [G loss: -0.108932]\n",
            "45 [D loss: 0.440476, acc.: 52.51%] [G loss: -0.279180]\n",
            "46 [D loss: 0.446211, acc.: 54.43%] [G loss: -0.055922]\n",
            "47 [D loss: 0.476406, acc.: 51.93%] [G loss: -0.197035]\n",
            "48 [D loss: 0.435091, acc.: 53.02%] [G loss: -0.138816]\n",
            "49 [D loss: 0.417997, acc.: 53.92%] [G loss: -0.139976]\n",
            "50 [D loss: 0.408354, acc.: 53.22%] [G loss: -0.151376]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "51 [D loss: 0.407784, acc.: 53.39%] [G loss: -0.137910]\n",
            "52 [D loss: 0.404831, acc.: 53.20%] [G loss: -0.156344]\n",
            "53 [D loss: 0.404862, acc.: 52.65%] [G loss: -0.184032]\n",
            "54 [D loss: 0.404705, acc.: 52.76%] [G loss: -0.150195]\n",
            "55 [D loss: 0.402752, acc.: 53.45%] [G loss: -0.140580]\n",
            "56 [D loss: 0.404897, acc.: 52.47%] [G loss: -0.188167]\n",
            "57 [D loss: 0.406454, acc.: 53.26%] [G loss: -0.138983]\n",
            "58 [D loss: 0.406259, acc.: 52.59%] [G loss: -0.162327]\n",
            "59 [D loss: 0.402249, acc.: 53.30%] [G loss: -0.144934]\n",
            "60 [D loss: 0.402851, acc.: 52.49%] [G loss: -0.137667]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "61 [D loss: 0.401674, acc.: 53.10%] [G loss: -0.150654]\n",
            "62 [D loss: 0.400689, acc.: 52.57%] [G loss: -0.149907]\n",
            "63 [D loss: 0.401401, acc.: 52.24%] [G loss: -0.181486]\n",
            "64 [D loss: 0.401805, acc.: 52.33%] [G loss: -0.147515]\n",
            "65 [D loss: 0.400127, acc.: 52.94%] [G loss: -0.137524]\n",
            "66 [D loss: 0.402110, acc.: 51.89%] [G loss: -0.182507]\n",
            "67 [D loss: 0.402369, acc.: 52.36%] [G loss: -0.146187]\n",
            "68 [D loss: 0.402129, acc.: 52.10%] [G loss: -0.157774]\n",
            "69 [D loss: 0.399420, acc.: 52.32%] [G loss: -0.149638]\n",
            "70 [D loss: 0.400530, acc.: 51.90%] [G loss: -0.137866]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n",
            "71 [D loss: 0.400264, acc.: 52.26%] [G loss: -0.155580]\n",
            "72 [D loss: 0.398859, acc.: 51.86%] [G loss: -0.150868]\n",
            "73 [D loss: 0.399280, acc.: 51.36%] [G loss: -0.190719]\n",
            "74 [D loss: 0.399872, acc.: 51.63%] [G loss: -0.153097]\n",
            "75 [D loss: 0.398603, acc.: 51.93%] [G loss: -0.140749]\n",
            "76 [D loss: 0.400509, acc.: 51.04%] [G loss: -0.180159]\n",
            "77 [D loss: 0.399730, acc.: 51.30%] [G loss: -0.159881]\n",
            "78 [D loss: 0.399251, acc.: 51.30%] [G loss: -0.153898]\n",
            "79 [D loss: 0.397879, acc.: 51.11%] [G loss: -0.160105]\n",
            "80 [D loss: 0.399690, acc.: 50.98%] [G loss: -0.139594]\n",
            "Dataset loaded.\n",
            "img :  (?, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-30e55d583d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/test_images.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-903ed60bb2ab>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_sample_%06d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_gan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-903ed60bb2ab>\u001b[0m in \u001b[0;36msave_gan_model\u001b[0;34m(self, model_file)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mgan_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_gan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mpickle_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mlayer_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "po1Im1Qg1NWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan.sample_images('images/test_images2_12.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kRuuKf9MFzgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im = Image.open(\"drive/My Drive/texture/patchset3/patchno\"+str(0)+\".jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o6uUaXwsF6Sl",
        "colab_type": "code",
        "outputId": "17b843fc-51fc-4487-fecf-3326095cfef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f408db00b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wGwrxWfLGLyR",
        "colab_type": "code",
        "outputId": "438b9f6e-f150-4680-d24e-4f53ac21db4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(im).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "daKr6S4XKvV3",
        "colab_type": "code",
        "outputId": "48d04ccc-826d-4e42-b2d8-ec5e3b42a131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.max(im)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "HShiehElZF98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}