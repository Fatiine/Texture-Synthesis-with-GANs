{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "SoWrq1S3KVGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pdb\n",
        "import pickle\n",
        "import copy\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_5PeK4sDKEl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        # Input shape\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((7, 7, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random half of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            # Sample noise and generate a batch of new images\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            # Train the generator (wants discriminator to mistake images as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFm4gSEJKb2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 21882
        },
        "outputId": "8faeed6e-5e12-4064-b241-de8a972cda7c"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  #create the output image and model directories\n",
        "  if (os.path.isdir('images')==0):\n",
        "    os.mkdir('images')\n",
        "  if (os.path.isdir('models')==0):\n",
        "    os.mkdir('models')\n",
        "\n",
        "  #choose dataset\n",
        "  dataset_name = 'mnist'#\n",
        "\n",
        "  #create GAN model\n",
        "  set_session(session)\n",
        "\n",
        "  #create GAN model\n",
        "  dcgan = DCGAN()\n",
        "  dcgan.train(epochs=4000, batch_size=32, save_interval=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 393,729\n",
            "Trainable params: 392,833\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 856,193\n",
            "Trainable params: 855,809\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.948770, acc.: 39.06%] [G loss: 0.763817]\n",
            "1 [D loss: 0.542557, acc.: 73.44%] [G loss: 1.332557]\n",
            "2 [D loss: 0.388632, acc.: 84.38%] [G loss: 1.793581]\n",
            "3 [D loss: 0.378687, acc.: 79.69%] [G loss: 2.020420]\n",
            "4 [D loss: 0.482661, acc.: 71.88%] [G loss: 2.308644]\n",
            "5 [D loss: 0.508799, acc.: 76.56%] [G loss: 3.243108]\n",
            "6 [D loss: 0.493594, acc.: 75.00%] [G loss: 3.028686]\n",
            "7 [D loss: 0.667447, acc.: 60.94%] [G loss: 2.722117]\n",
            "8 [D loss: 0.719218, acc.: 60.94%] [G loss: 2.330084]\n",
            "9 [D loss: 0.550196, acc.: 71.88%] [G loss: 2.486082]\n",
            "10 [D loss: 0.523302, acc.: 73.44%] [G loss: 1.792382]\n",
            "11 [D loss: 0.578550, acc.: 68.75%] [G loss: 1.754393]\n",
            "12 [D loss: 0.297471, acc.: 92.19%] [G loss: 1.822448]\n",
            "13 [D loss: 0.174136, acc.: 98.44%] [G loss: 1.290140]\n",
            "14 [D loss: 0.223949, acc.: 93.75%] [G loss: 0.829269]\n",
            "15 [D loss: 0.167837, acc.: 95.31%] [G loss: 0.560440]\n",
            "16 [D loss: 0.227899, acc.: 93.75%] [G loss: 0.435169]\n",
            "17 [D loss: 0.140658, acc.: 96.88%] [G loss: 0.706996]\n",
            "18 [D loss: 0.262720, acc.: 89.06%] [G loss: 1.076267]\n",
            "19 [D loss: 0.518497, acc.: 73.44%] [G loss: 1.148970]\n",
            "20 [D loss: 1.003381, acc.: 40.62%] [G loss: 1.394716]\n",
            "21 [D loss: 0.877208, acc.: 51.56%] [G loss: 2.494541]\n",
            "22 [D loss: 1.271065, acc.: 42.19%] [G loss: 1.609712]\n",
            "23 [D loss: 0.904325, acc.: 45.31%] [G loss: 1.551712]\n",
            "24 [D loss: 0.867539, acc.: 59.38%] [G loss: 1.618995]\n",
            "25 [D loss: 0.710286, acc.: 57.81%] [G loss: 1.285862]\n",
            "26 [D loss: 0.776502, acc.: 56.25%] [G loss: 1.314744]\n",
            "27 [D loss: 0.645838, acc.: 68.75%] [G loss: 0.960167]\n",
            "28 [D loss: 0.586384, acc.: 70.31%] [G loss: 0.558926]\n",
            "29 [D loss: 0.712214, acc.: 67.19%] [G loss: 1.040101]\n",
            "30 [D loss: 0.660710, acc.: 62.50%] [G loss: 1.276726]\n",
            "31 [D loss: 1.359223, acc.: 28.12%] [G loss: 1.485207]\n",
            "32 [D loss: 1.098622, acc.: 35.94%] [G loss: 1.383620]\n",
            "33 [D loss: 0.954888, acc.: 46.88%] [G loss: 0.980695]\n",
            "34 [D loss: 0.987727, acc.: 42.19%] [G loss: 1.309083]\n",
            "35 [D loss: 0.924515, acc.: 45.31%] [G loss: 1.421866]\n",
            "36 [D loss: 0.987786, acc.: 45.31%] [G loss: 1.472680]\n",
            "37 [D loss: 1.185807, acc.: 42.19%] [G loss: 1.881081]\n",
            "38 [D loss: 0.879830, acc.: 45.31%] [G loss: 1.584552]\n",
            "39 [D loss: 0.738709, acc.: 60.94%] [G loss: 1.319881]\n",
            "40 [D loss: 0.771977, acc.: 54.69%] [G loss: 1.137104]\n",
            "41 [D loss: 0.819490, acc.: 51.56%] [G loss: 1.642573]\n",
            "42 [D loss: 0.821548, acc.: 60.94%] [G loss: 1.723861]\n",
            "43 [D loss: 0.995544, acc.: 50.00%] [G loss: 1.739142]\n",
            "44 [D loss: 0.856584, acc.: 40.62%] [G loss: 1.339516]\n",
            "45 [D loss: 0.746205, acc.: 54.69%] [G loss: 1.299600]\n",
            "46 [D loss: 0.706987, acc.: 60.94%] [G loss: 1.186507]\n",
            "47 [D loss: 0.789305, acc.: 56.25%] [G loss: 1.145977]\n",
            "48 [D loss: 0.957365, acc.: 50.00%] [G loss: 1.352697]\n",
            "49 [D loss: 1.037264, acc.: 34.38%] [G loss: 1.658472]\n",
            "50 [D loss: 0.948322, acc.: 48.44%] [G loss: 1.454652]\n",
            "51 [D loss: 1.039761, acc.: 39.06%] [G loss: 1.365170]\n",
            "52 [D loss: 0.864333, acc.: 51.56%] [G loss: 1.322764]\n",
            "53 [D loss: 0.882089, acc.: 42.19%] [G loss: 1.463422]\n",
            "54 [D loss: 1.048463, acc.: 45.31%] [G loss: 1.606869]\n",
            "55 [D loss: 0.872089, acc.: 46.88%] [G loss: 1.594371]\n",
            "56 [D loss: 0.885157, acc.: 53.12%] [G loss: 1.162546]\n",
            "57 [D loss: 0.829200, acc.: 50.00%] [G loss: 1.090880]\n",
            "58 [D loss: 0.710149, acc.: 62.50%] [G loss: 0.934591]\n",
            "59 [D loss: 0.757982, acc.: 60.94%] [G loss: 1.316281]\n",
            "60 [D loss: 0.817307, acc.: 57.81%] [G loss: 1.254966]\n",
            "61 [D loss: 1.110895, acc.: 37.50%] [G loss: 1.533295]\n",
            "62 [D loss: 0.813615, acc.: 46.88%] [G loss: 1.243713]\n",
            "63 [D loss: 1.076336, acc.: 42.19%] [G loss: 1.211878]\n",
            "64 [D loss: 0.797355, acc.: 57.81%] [G loss: 1.491394]\n",
            "65 [D loss: 0.854965, acc.: 54.69%] [G loss: 1.492359]\n",
            "66 [D loss: 0.605633, acc.: 68.75%] [G loss: 1.523990]\n",
            "67 [D loss: 0.826264, acc.: 51.56%] [G loss: 1.371403]\n",
            "68 [D loss: 0.853158, acc.: 51.56%] [G loss: 1.063216]\n",
            "69 [D loss: 0.882327, acc.: 48.44%] [G loss: 0.948230]\n",
            "70 [D loss: 0.542058, acc.: 68.75%] [G loss: 1.089965]\n",
            "71 [D loss: 0.775332, acc.: 62.50%] [G loss: 1.328362]\n",
            "72 [D loss: 0.849876, acc.: 51.56%] [G loss: 1.493002]\n",
            "73 [D loss: 0.919690, acc.: 40.62%] [G loss: 1.453560]\n",
            "74 [D loss: 0.921072, acc.: 51.56%] [G loss: 1.157269]\n",
            "75 [D loss: 0.959291, acc.: 46.88%] [G loss: 1.527242]\n",
            "76 [D loss: 0.652803, acc.: 59.38%] [G loss: 1.139963]\n",
            "77 [D loss: 0.960489, acc.: 53.12%] [G loss: 1.485021]\n",
            "78 [D loss: 0.920510, acc.: 45.31%] [G loss: 1.428679]\n",
            "79 [D loss: 0.754560, acc.: 65.62%] [G loss: 1.281745]\n",
            "80 [D loss: 0.952080, acc.: 50.00%] [G loss: 1.476306]\n",
            "81 [D loss: 0.992055, acc.: 50.00%] [G loss: 1.344779]\n",
            "82 [D loss: 0.793375, acc.: 53.12%] [G loss: 1.155363]\n",
            "83 [D loss: 0.777454, acc.: 56.25%] [G loss: 1.111122]\n",
            "84 [D loss: 0.810462, acc.: 56.25%] [G loss: 1.524502]\n",
            "85 [D loss: 0.996653, acc.: 45.31%] [G loss: 1.318228]\n",
            "86 [D loss: 0.782067, acc.: 56.25%] [G loss: 1.367240]\n",
            "87 [D loss: 1.066747, acc.: 42.19%] [G loss: 1.216810]\n",
            "88 [D loss: 0.815647, acc.: 54.69%] [G loss: 1.263131]\n",
            "89 [D loss: 0.962633, acc.: 48.44%] [G loss: 1.243006]\n",
            "90 [D loss: 0.873277, acc.: 42.19%] [G loss: 1.427990]\n",
            "91 [D loss: 0.782173, acc.: 56.25%] [G loss: 1.606503]\n",
            "92 [D loss: 0.855374, acc.: 56.25%] [G loss: 1.520590]\n",
            "93 [D loss: 0.960743, acc.: 53.12%] [G loss: 1.185908]\n",
            "94 [D loss: 0.819739, acc.: 50.00%] [G loss: 1.323843]\n",
            "95 [D loss: 0.842034, acc.: 57.81%] [G loss: 1.094074]\n",
            "96 [D loss: 0.867828, acc.: 48.44%] [G loss: 1.307796]\n",
            "97 [D loss: 0.980249, acc.: 39.06%] [G loss: 1.194149]\n",
            "98 [D loss: 0.868335, acc.: 42.19%] [G loss: 1.157932]\n",
            "99 [D loss: 0.722856, acc.: 57.81%] [G loss: 1.316844]\n",
            "100 [D loss: 0.868434, acc.: 46.88%] [G loss: 1.127600]\n",
            "101 [D loss: 0.800922, acc.: 54.69%] [G loss: 1.147407]\n",
            "102 [D loss: 0.903981, acc.: 45.31%] [G loss: 1.024912]\n",
            "103 [D loss: 0.828264, acc.: 50.00%] [G loss: 1.147324]\n",
            "104 [D loss: 0.984110, acc.: 43.75%] [G loss: 0.997959]\n",
            "105 [D loss: 0.978050, acc.: 34.38%] [G loss: 1.377822]\n",
            "106 [D loss: 0.970260, acc.: 34.38%] [G loss: 1.238096]\n",
            "107 [D loss: 0.914220, acc.: 51.56%] [G loss: 1.330822]\n",
            "108 [D loss: 1.010669, acc.: 37.50%] [G loss: 1.108082]\n",
            "109 [D loss: 0.904097, acc.: 43.75%] [G loss: 1.180591]\n",
            "110 [D loss: 0.830685, acc.: 54.69%] [G loss: 1.473238]\n",
            "111 [D loss: 0.903750, acc.: 40.62%] [G loss: 1.119267]\n",
            "112 [D loss: 0.931032, acc.: 37.50%] [G loss: 1.238564]\n",
            "113 [D loss: 0.901712, acc.: 45.31%] [G loss: 1.255691]\n",
            "114 [D loss: 0.865841, acc.: 43.75%] [G loss: 1.081253]\n",
            "115 [D loss: 0.980720, acc.: 37.50%] [G loss: 1.355145]\n",
            "116 [D loss: 0.797213, acc.: 54.69%] [G loss: 1.330850]\n",
            "117 [D loss: 0.978670, acc.: 39.06%] [G loss: 1.354556]\n",
            "118 [D loss: 0.617355, acc.: 67.19%] [G loss: 1.467164]\n",
            "119 [D loss: 0.861477, acc.: 46.88%] [G loss: 1.043239]\n",
            "120 [D loss: 0.763485, acc.: 62.50%] [G loss: 1.140452]\n",
            "121 [D loss: 0.800071, acc.: 51.56%] [G loss: 1.206289]\n",
            "122 [D loss: 0.943955, acc.: 39.06%] [G loss: 1.007795]\n",
            "123 [D loss: 0.729241, acc.: 59.38%] [G loss: 1.163544]\n",
            "124 [D loss: 0.823658, acc.: 45.31%] [G loss: 0.942936]\n",
            "125 [D loss: 0.831864, acc.: 53.12%] [G loss: 1.135012]\n",
            "126 [D loss: 0.859379, acc.: 48.44%] [G loss: 1.342846]\n",
            "127 [D loss: 0.984040, acc.: 37.50%] [G loss: 1.216514]\n",
            "128 [D loss: 0.830317, acc.: 43.75%] [G loss: 1.239453]\n",
            "129 [D loss: 0.796605, acc.: 45.31%] [G loss: 1.151366]\n",
            "130 [D loss: 0.780497, acc.: 53.12%] [G loss: 1.036704]\n",
            "131 [D loss: 0.950243, acc.: 45.31%] [G loss: 1.055768]\n",
            "132 [D loss: 0.727120, acc.: 64.06%] [G loss: 1.141789]\n",
            "133 [D loss: 0.909332, acc.: 46.88%] [G loss: 1.131850]\n",
            "134 [D loss: 0.918608, acc.: 45.31%] [G loss: 1.252792]\n",
            "135 [D loss: 0.767547, acc.: 51.56%] [G loss: 1.174056]\n",
            "136 [D loss: 0.865653, acc.: 45.31%] [G loss: 1.183895]\n",
            "137 [D loss: 0.929268, acc.: 46.88%] [G loss: 0.907086]\n",
            "138 [D loss: 0.917056, acc.: 42.19%] [G loss: 1.506620]\n",
            "139 [D loss: 0.725561, acc.: 57.81%] [G loss: 1.293444]\n",
            "140 [D loss: 0.729188, acc.: 60.94%] [G loss: 1.271919]\n",
            "141 [D loss: 0.904482, acc.: 46.88%] [G loss: 1.139135]\n",
            "142 [D loss: 0.868834, acc.: 56.25%] [G loss: 1.293302]\n",
            "143 [D loss: 0.845970, acc.: 53.12%] [G loss: 1.003038]\n",
            "144 [D loss: 1.135429, acc.: 32.81%] [G loss: 0.960713]\n",
            "145 [D loss: 0.844069, acc.: 48.44%] [G loss: 1.104868]\n",
            "146 [D loss: 0.858053, acc.: 54.69%] [G loss: 0.976581]\n",
            "147 [D loss: 0.876400, acc.: 46.88%] [G loss: 1.204757]\n",
            "148 [D loss: 0.780466, acc.: 53.12%] [G loss: 1.244048]\n",
            "149 [D loss: 0.941435, acc.: 35.94%] [G loss: 1.075313]\n",
            "150 [D loss: 0.922666, acc.: 32.81%] [G loss: 1.067406]\n",
            "151 [D loss: 0.935882, acc.: 40.62%] [G loss: 1.146414]\n",
            "152 [D loss: 1.006446, acc.: 29.69%] [G loss: 1.021420]\n",
            "153 [D loss: 1.024509, acc.: 37.50%] [G loss: 1.182927]\n",
            "154 [D loss: 0.898097, acc.: 40.62%] [G loss: 1.059837]\n",
            "155 [D loss: 0.735372, acc.: 56.25%] [G loss: 1.062249]\n",
            "156 [D loss: 0.927783, acc.: 42.19%] [G loss: 1.395374]\n",
            "157 [D loss: 0.758589, acc.: 48.44%] [G loss: 1.522171]\n",
            "158 [D loss: 0.906233, acc.: 37.50%] [G loss: 1.235185]\n",
            "159 [D loss: 0.925439, acc.: 43.75%] [G loss: 1.352343]\n",
            "160 [D loss: 0.897157, acc.: 35.94%] [G loss: 1.212244]\n",
            "161 [D loss: 0.929273, acc.: 48.44%] [G loss: 1.334722]\n",
            "162 [D loss: 0.987615, acc.: 35.94%] [G loss: 1.193184]\n",
            "163 [D loss: 0.889693, acc.: 40.62%] [G loss: 1.001690]\n",
            "164 [D loss: 0.721947, acc.: 60.94%] [G loss: 1.191897]\n",
            "165 [D loss: 0.836254, acc.: 43.75%] [G loss: 1.012171]\n",
            "166 [D loss: 0.861147, acc.: 50.00%] [G loss: 1.046553]\n",
            "167 [D loss: 0.801645, acc.: 53.12%] [G loss: 1.020276]\n",
            "168 [D loss: 0.861807, acc.: 39.06%] [G loss: 0.985948]\n",
            "169 [D loss: 0.916325, acc.: 40.62%] [G loss: 0.975129]\n",
            "170 [D loss: 0.663383, acc.: 62.50%] [G loss: 1.270810]\n",
            "171 [D loss: 0.691928, acc.: 65.62%] [G loss: 1.106816]\n",
            "172 [D loss: 0.835532, acc.: 48.44%] [G loss: 0.952529]\n",
            "173 [D loss: 0.738037, acc.: 51.56%] [G loss: 1.148566]\n",
            "174 [D loss: 0.806106, acc.: 57.81%] [G loss: 1.158620]\n",
            "175 [D loss: 0.870627, acc.: 46.88%] [G loss: 0.965662]\n",
            "176 [D loss: 0.839036, acc.: 51.56%] [G loss: 1.217620]\n",
            "177 [D loss: 0.797127, acc.: 54.69%] [G loss: 0.915102]\n",
            "178 [D loss: 0.838130, acc.: 51.56%] [G loss: 1.152775]\n",
            "179 [D loss: 0.883694, acc.: 43.75%] [G loss: 1.023276]\n",
            "180 [D loss: 0.932555, acc.: 46.88%] [G loss: 0.946616]\n",
            "181 [D loss: 0.868150, acc.: 39.06%] [G loss: 1.122022]\n",
            "182 [D loss: 0.851809, acc.: 48.44%] [G loss: 1.211957]\n",
            "183 [D loss: 0.989305, acc.: 40.62%] [G loss: 1.267047]\n",
            "184 [D loss: 0.874164, acc.: 46.88%] [G loss: 1.054296]\n",
            "185 [D loss: 1.114688, acc.: 29.69%] [G loss: 1.066147]\n",
            "186 [D loss: 0.920460, acc.: 45.31%] [G loss: 0.984905]\n",
            "187 [D loss: 0.763289, acc.: 45.31%] [G loss: 1.289980]\n",
            "188 [D loss: 0.789936, acc.: 42.19%] [G loss: 1.227741]\n",
            "189 [D loss: 0.916402, acc.: 39.06%] [G loss: 0.991844]\n",
            "190 [D loss: 0.887166, acc.: 39.06%] [G loss: 1.132341]\n",
            "191 [D loss: 0.855021, acc.: 45.31%] [G loss: 1.047440]\n",
            "192 [D loss: 0.801532, acc.: 54.69%] [G loss: 1.206347]\n",
            "193 [D loss: 0.735230, acc.: 60.94%] [G loss: 1.118107]\n",
            "194 [D loss: 0.843199, acc.: 39.06%] [G loss: 0.957361]\n",
            "195 [D loss: 0.726888, acc.: 46.88%] [G loss: 1.225382]\n",
            "196 [D loss: 0.714079, acc.: 53.12%] [G loss: 1.005306]\n",
            "197 [D loss: 0.901244, acc.: 37.50%] [G loss: 1.115778]\n",
            "198 [D loss: 0.766157, acc.: 56.25%] [G loss: 0.960518]\n",
            "199 [D loss: 0.747023, acc.: 56.25%] [G loss: 1.200137]\n",
            "200 [D loss: 0.944172, acc.: 34.38%] [G loss: 1.166943]\n",
            "201 [D loss: 0.847152, acc.: 42.19%] [G loss: 1.246748]\n",
            "202 [D loss: 0.779559, acc.: 51.56%] [G loss: 1.145666]\n",
            "203 [D loss: 0.808485, acc.: 43.75%] [G loss: 0.788277]\n",
            "204 [D loss: 0.847013, acc.: 42.19%] [G loss: 0.873319]\n",
            "205 [D loss: 0.856814, acc.: 45.31%] [G loss: 1.204574]\n",
            "206 [D loss: 0.855430, acc.: 43.75%] [G loss: 1.070288]\n",
            "207 [D loss: 0.848788, acc.: 37.50%] [G loss: 1.024087]\n",
            "208 [D loss: 0.889094, acc.: 37.50%] [G loss: 0.891300]\n",
            "209 [D loss: 0.827942, acc.: 48.44%] [G loss: 1.016054]\n",
            "210 [D loss: 0.992807, acc.: 28.12%] [G loss: 0.827278]\n",
            "211 [D loss: 0.842577, acc.: 43.75%] [G loss: 1.185607]\n",
            "212 [D loss: 0.845902, acc.: 46.88%] [G loss: 1.067209]\n",
            "213 [D loss: 0.852810, acc.: 42.19%] [G loss: 1.218265]\n",
            "214 [D loss: 0.882056, acc.: 40.62%] [G loss: 0.984494]\n",
            "215 [D loss: 0.804348, acc.: 51.56%] [G loss: 1.026285]\n",
            "216 [D loss: 0.736575, acc.: 53.12%] [G loss: 1.000850]\n",
            "217 [D loss: 0.803304, acc.: 50.00%] [G loss: 1.017927]\n",
            "218 [D loss: 0.671549, acc.: 60.94%] [G loss: 1.181594]\n",
            "219 [D loss: 0.706824, acc.: 53.12%] [G loss: 1.387716]\n",
            "220 [D loss: 0.917707, acc.: 35.94%] [G loss: 1.152269]\n",
            "221 [D loss: 0.907471, acc.: 45.31%] [G loss: 1.090140]\n",
            "222 [D loss: 0.959673, acc.: 34.38%] [G loss: 0.906561]\n",
            "223 [D loss: 0.720578, acc.: 64.06%] [G loss: 1.106664]\n",
            "224 [D loss: 0.832548, acc.: 43.75%] [G loss: 1.055176]\n",
            "225 [D loss: 0.799726, acc.: 51.56%] [G loss: 1.059447]\n",
            "226 [D loss: 0.770610, acc.: 42.19%] [G loss: 1.077264]\n",
            "227 [D loss: 0.699613, acc.: 53.12%] [G loss: 0.848605]\n",
            "228 [D loss: 0.774853, acc.: 56.25%] [G loss: 1.423195]\n",
            "229 [D loss: 0.713535, acc.: 56.25%] [G loss: 1.152638]\n",
            "230 [D loss: 0.856073, acc.: 51.56%] [G loss: 1.208077]\n",
            "231 [D loss: 0.892596, acc.: 45.31%] [G loss: 1.020728]\n",
            "232 [D loss: 0.809338, acc.: 40.62%] [G loss: 1.004988]\n",
            "233 [D loss: 0.750672, acc.: 50.00%] [G loss: 1.253618]\n",
            "234 [D loss: 0.831691, acc.: 45.31%] [G loss: 1.038703]\n",
            "235 [D loss: 0.806106, acc.: 46.88%] [G loss: 0.838025]\n",
            "236 [D loss: 0.885832, acc.: 42.19%] [G loss: 1.090136]\n",
            "237 [D loss: 0.743890, acc.: 51.56%] [G loss: 1.103032]\n",
            "238 [D loss: 0.825981, acc.: 43.75%] [G loss: 1.211467]\n",
            "239 [D loss: 0.687461, acc.: 56.25%] [G loss: 1.094068]\n",
            "240 [D loss: 0.827487, acc.: 45.31%] [G loss: 1.078560]\n",
            "241 [D loss: 0.907175, acc.: 31.25%] [G loss: 0.968763]\n",
            "242 [D loss: 0.798431, acc.: 45.31%] [G loss: 1.135825]\n",
            "243 [D loss: 0.898952, acc.: 43.75%] [G loss: 0.917390]\n",
            "244 [D loss: 0.823275, acc.: 46.88%] [G loss: 1.107930]\n",
            "245 [D loss: 0.751647, acc.: 59.38%] [G loss: 1.143176]\n",
            "246 [D loss: 0.805671, acc.: 42.19%] [G loss: 1.052810]\n",
            "247 [D loss: 0.827471, acc.: 42.19%] [G loss: 1.054690]\n",
            "248 [D loss: 0.807638, acc.: 40.62%] [G loss: 1.117369]\n",
            "249 [D loss: 0.857941, acc.: 32.81%] [G loss: 0.978517]\n",
            "250 [D loss: 0.833214, acc.: 42.19%] [G loss: 1.094618]\n",
            "251 [D loss: 0.858739, acc.: 53.12%] [G loss: 1.341998]\n",
            "252 [D loss: 0.804414, acc.: 42.19%] [G loss: 1.186588]\n",
            "253 [D loss: 0.705569, acc.: 51.56%] [G loss: 0.984444]\n",
            "254 [D loss: 0.823431, acc.: 51.56%] [G loss: 1.043159]\n",
            "255 [D loss: 0.969402, acc.: 32.81%] [G loss: 1.054573]\n",
            "256 [D loss: 0.673789, acc.: 59.38%] [G loss: 1.182394]\n",
            "257 [D loss: 0.833330, acc.: 45.31%] [G loss: 0.999332]\n",
            "258 [D loss: 0.767196, acc.: 54.69%] [G loss: 1.141338]\n",
            "259 [D loss: 0.891345, acc.: 40.62%] [G loss: 0.987676]\n",
            "260 [D loss: 0.828420, acc.: 40.62%] [G loss: 0.975791]\n",
            "261 [D loss: 0.885294, acc.: 43.75%] [G loss: 1.104176]\n",
            "262 [D loss: 0.813446, acc.: 48.44%] [G loss: 1.044096]\n",
            "263 [D loss: 0.746919, acc.: 54.69%] [G loss: 1.140168]\n",
            "264 [D loss: 0.935174, acc.: 40.62%] [G loss: 1.160260]\n",
            "265 [D loss: 0.923064, acc.: 37.50%] [G loss: 1.205204]\n",
            "266 [D loss: 0.917598, acc.: 31.25%] [G loss: 1.125201]\n",
            "267 [D loss: 0.797264, acc.: 53.12%] [G loss: 1.128379]\n",
            "268 [D loss: 0.875433, acc.: 45.31%] [G loss: 1.063395]\n",
            "269 [D loss: 0.828691, acc.: 42.19%] [G loss: 1.038825]\n",
            "270 [D loss: 0.727066, acc.: 51.56%] [G loss: 1.199441]\n",
            "271 [D loss: 0.896677, acc.: 40.62%] [G loss: 1.071211]\n",
            "272 [D loss: 0.930238, acc.: 32.81%] [G loss: 1.033440]\n",
            "273 [D loss: 0.731268, acc.: 56.25%] [G loss: 1.131022]\n",
            "274 [D loss: 0.796116, acc.: 46.88%] [G loss: 0.925114]\n",
            "275 [D loss: 0.727236, acc.: 59.38%] [G loss: 1.337734]\n",
            "276 [D loss: 0.673599, acc.: 64.06%] [G loss: 1.144792]\n",
            "277 [D loss: 0.787450, acc.: 45.31%] [G loss: 1.120399]\n",
            "278 [D loss: 0.732313, acc.: 53.12%] [G loss: 1.141607]\n",
            "279 [D loss: 0.794019, acc.: 42.19%] [G loss: 1.055599]\n",
            "280 [D loss: 0.828202, acc.: 51.56%] [G loss: 0.939541]\n",
            "281 [D loss: 0.965931, acc.: 35.94%] [G loss: 0.978222]\n",
            "282 [D loss: 0.739885, acc.: 56.25%] [G loss: 1.084683]\n",
            "283 [D loss: 0.907992, acc.: 40.62%] [G loss: 1.188813]\n",
            "284 [D loss: 0.720443, acc.: 54.69%] [G loss: 1.150574]\n",
            "285 [D loss: 0.794935, acc.: 53.12%] [G loss: 1.030154]\n",
            "286 [D loss: 0.892908, acc.: 50.00%] [G loss: 1.032879]\n",
            "287 [D loss: 0.753735, acc.: 51.56%] [G loss: 0.919440]\n",
            "288 [D loss: 0.802376, acc.: 46.88%] [G loss: 1.048333]\n",
            "289 [D loss: 0.764000, acc.: 53.12%] [G loss: 1.241191]\n",
            "290 [D loss: 0.883707, acc.: 46.88%] [G loss: 0.977544]\n",
            "291 [D loss: 0.754209, acc.: 56.25%] [G loss: 0.987749]\n",
            "292 [D loss: 0.705427, acc.: 53.12%] [G loss: 1.053217]\n",
            "293 [D loss: 0.840103, acc.: 42.19%] [G loss: 0.894801]\n",
            "294 [D loss: 0.854307, acc.: 46.88%] [G loss: 1.175545]\n",
            "295 [D loss: 0.755294, acc.: 46.88%] [G loss: 0.958260]\n",
            "296 [D loss: 0.901363, acc.: 35.94%] [G loss: 0.917992]\n",
            "297 [D loss: 0.846817, acc.: 43.75%] [G loss: 1.136730]\n",
            "298 [D loss: 0.775927, acc.: 51.56%] [G loss: 0.973160]\n",
            "299 [D loss: 0.691345, acc.: 54.69%] [G loss: 1.111872]\n",
            "300 [D loss: 0.855025, acc.: 40.62%] [G loss: 1.090200]\n",
            "301 [D loss: 0.719362, acc.: 60.94%] [G loss: 1.017094]\n",
            "302 [D loss: 0.940539, acc.: 34.38%] [G loss: 1.009593]\n",
            "303 [D loss: 0.866369, acc.: 42.19%] [G loss: 0.946691]\n",
            "304 [D loss: 0.995791, acc.: 32.81%] [G loss: 0.846982]\n",
            "305 [D loss: 0.796552, acc.: 50.00%] [G loss: 0.989023]\n",
            "306 [D loss: 0.792051, acc.: 43.75%] [G loss: 1.066191]\n",
            "307 [D loss: 0.764693, acc.: 53.12%] [G loss: 1.076062]\n",
            "308 [D loss: 0.782603, acc.: 53.12%] [G loss: 1.011102]\n",
            "309 [D loss: 0.827794, acc.: 42.19%] [G loss: 0.895563]\n",
            "310 [D loss: 0.838353, acc.: 46.88%] [G loss: 1.053242]\n",
            "311 [D loss: 0.668702, acc.: 60.94%] [G loss: 0.979674]\n",
            "312 [D loss: 0.734030, acc.: 54.69%] [G loss: 1.114667]\n",
            "313 [D loss: 0.820269, acc.: 46.88%] [G loss: 0.870096]\n",
            "314 [D loss: 0.774880, acc.: 53.12%] [G loss: 1.142771]\n",
            "315 [D loss: 0.853103, acc.: 37.50%] [G loss: 1.121518]\n",
            "316 [D loss: 0.865001, acc.: 42.19%] [G loss: 0.907812]\n",
            "317 [D loss: 0.874793, acc.: 43.75%] [G loss: 0.985116]\n",
            "318 [D loss: 0.865108, acc.: 37.50%] [G loss: 0.851874]\n",
            "319 [D loss: 0.836884, acc.: 48.44%] [G loss: 0.893762]\n",
            "320 [D loss: 0.824034, acc.: 51.56%] [G loss: 0.911175]\n",
            "321 [D loss: 0.771575, acc.: 53.12%] [G loss: 0.918825]\n",
            "322 [D loss: 0.768715, acc.: 50.00%] [G loss: 1.040039]\n",
            "323 [D loss: 0.755610, acc.: 48.44%] [G loss: 0.850489]\n",
            "324 [D loss: 0.801489, acc.: 37.50%] [G loss: 0.967184]\n",
            "325 [D loss: 0.841191, acc.: 42.19%] [G loss: 0.889420]\n",
            "326 [D loss: 0.823476, acc.: 50.00%] [G loss: 0.933546]\n",
            "327 [D loss: 0.821285, acc.: 40.62%] [G loss: 0.751620]\n",
            "328 [D loss: 0.892007, acc.: 39.06%] [G loss: 0.809892]\n",
            "329 [D loss: 0.827239, acc.: 53.12%] [G loss: 1.215314]\n",
            "330 [D loss: 0.800642, acc.: 53.12%] [G loss: 1.209250]\n",
            "331 [D loss: 0.784975, acc.: 48.44%] [G loss: 1.247818]\n",
            "332 [D loss: 0.961699, acc.: 40.62%] [G loss: 1.021463]\n",
            "333 [D loss: 0.797864, acc.: 50.00%] [G loss: 0.985032]\n",
            "334 [D loss: 0.878232, acc.: 39.06%] [G loss: 1.002137]\n",
            "335 [D loss: 0.703772, acc.: 59.38%] [G loss: 0.941978]\n",
            "336 [D loss: 0.841889, acc.: 43.75%] [G loss: 0.979654]\n",
            "337 [D loss: 0.772627, acc.: 53.12%] [G loss: 0.847944]\n",
            "338 [D loss: 0.850074, acc.: 43.75%] [G loss: 0.996390]\n",
            "339 [D loss: 0.853618, acc.: 40.62%] [G loss: 0.965268]\n",
            "340 [D loss: 0.749746, acc.: 46.88%] [G loss: 0.930040]\n",
            "341 [D loss: 0.771546, acc.: 56.25%] [G loss: 0.984446]\n",
            "342 [D loss: 0.728551, acc.: 53.12%] [G loss: 1.053586]\n",
            "343 [D loss: 0.742117, acc.: 51.56%] [G loss: 1.097877]\n",
            "344 [D loss: 0.745589, acc.: 45.31%] [G loss: 1.005270]\n",
            "345 [D loss: 0.722900, acc.: 57.81%] [G loss: 0.979228]\n",
            "346 [D loss: 0.751245, acc.: 54.69%] [G loss: 1.039386]\n",
            "347 [D loss: 0.712523, acc.: 54.69%] [G loss: 1.256493]\n",
            "348 [D loss: 0.815251, acc.: 43.75%] [G loss: 0.998095]\n",
            "349 [D loss: 0.851781, acc.: 39.06%] [G loss: 1.217630]\n",
            "350 [D loss: 0.775054, acc.: 50.00%] [G loss: 1.125996]\n",
            "351 [D loss: 0.806212, acc.: 46.88%] [G loss: 1.078598]\n",
            "352 [D loss: 0.684726, acc.: 56.25%] [G loss: 0.971551]\n",
            "353 [D loss: 0.879834, acc.: 40.62%] [G loss: 0.871501]\n",
            "354 [D loss: 0.797024, acc.: 48.44%] [G loss: 1.270615]\n",
            "355 [D loss: 0.831560, acc.: 43.75%] [G loss: 1.117566]\n",
            "356 [D loss: 0.871345, acc.: 43.75%] [G loss: 0.887917]\n",
            "357 [D loss: 0.831608, acc.: 42.19%] [G loss: 0.887071]\n",
            "358 [D loss: 0.730164, acc.: 54.69%] [G loss: 1.017088]\n",
            "359 [D loss: 0.774860, acc.: 51.56%] [G loss: 1.007182]\n",
            "360 [D loss: 0.741395, acc.: 53.12%] [G loss: 1.091320]\n",
            "361 [D loss: 0.836945, acc.: 42.19%] [G loss: 1.168568]\n",
            "362 [D loss: 0.784661, acc.: 51.56%] [G loss: 1.062956]\n",
            "363 [D loss: 0.898109, acc.: 32.81%] [G loss: 0.966796]\n",
            "364 [D loss: 0.833308, acc.: 46.88%] [G loss: 1.045248]\n",
            "365 [D loss: 0.856258, acc.: 45.31%] [G loss: 0.956496]\n",
            "366 [D loss: 0.811883, acc.: 45.31%] [G loss: 0.871473]\n",
            "367 [D loss: 0.825241, acc.: 48.44%] [G loss: 1.229853]\n",
            "368 [D loss: 0.813589, acc.: 48.44%] [G loss: 0.973336]\n",
            "369 [D loss: 0.681164, acc.: 59.38%] [G loss: 0.915963]\n",
            "370 [D loss: 0.724446, acc.: 57.81%] [G loss: 0.883250]\n",
            "371 [D loss: 0.714059, acc.: 51.56%] [G loss: 1.167188]\n",
            "372 [D loss: 0.750961, acc.: 51.56%] [G loss: 0.968075]\n",
            "373 [D loss: 0.902883, acc.: 39.06%] [G loss: 1.030749]\n",
            "374 [D loss: 0.835341, acc.: 51.56%] [G loss: 0.962413]\n",
            "375 [D loss: 0.722699, acc.: 48.44%] [G loss: 0.970047]\n",
            "376 [D loss: 0.706683, acc.: 60.94%] [G loss: 0.983280]\n",
            "377 [D loss: 0.831587, acc.: 45.31%] [G loss: 1.051436]\n",
            "378 [D loss: 0.730809, acc.: 50.00%] [G loss: 1.083378]\n",
            "379 [D loss: 0.820237, acc.: 39.06%] [G loss: 0.992945]\n",
            "380 [D loss: 0.781301, acc.: 37.50%] [G loss: 0.961200]\n",
            "381 [D loss: 0.746196, acc.: 48.44%] [G loss: 0.947108]\n",
            "382 [D loss: 0.773790, acc.: 40.62%] [G loss: 0.743495]\n",
            "383 [D loss: 0.781665, acc.: 53.12%] [G loss: 1.238958]\n",
            "384 [D loss: 0.727472, acc.: 57.81%] [G loss: 0.767389]\n",
            "385 [D loss: 0.700295, acc.: 53.12%] [G loss: 0.999867]\n",
            "386 [D loss: 0.820963, acc.: 40.62%] [G loss: 0.997173]\n",
            "387 [D loss: 0.682656, acc.: 53.12%] [G loss: 1.255007]\n",
            "388 [D loss: 0.727467, acc.: 54.69%] [G loss: 1.015114]\n",
            "389 [D loss: 0.728690, acc.: 53.12%] [G loss: 1.055986]\n",
            "390 [D loss: 0.759927, acc.: 50.00%] [G loss: 0.944587]\n",
            "391 [D loss: 0.800958, acc.: 50.00%] [G loss: 0.963086]\n",
            "392 [D loss: 0.882918, acc.: 46.88%] [G loss: 1.082406]\n",
            "393 [D loss: 0.817163, acc.: 48.44%] [G loss: 0.950741]\n",
            "394 [D loss: 0.735490, acc.: 57.81%] [G loss: 1.086002]\n",
            "395 [D loss: 0.722259, acc.: 56.25%] [G loss: 1.008385]\n",
            "396 [D loss: 0.905253, acc.: 35.94%] [G loss: 1.111755]\n",
            "397 [D loss: 0.789427, acc.: 42.19%] [G loss: 1.005544]\n",
            "398 [D loss: 0.803668, acc.: 40.62%] [G loss: 1.055099]\n",
            "399 [D loss: 0.915315, acc.: 40.62%] [G loss: 0.992310]\n",
            "400 [D loss: 0.825710, acc.: 40.62%] [G loss: 1.001906]\n",
            "401 [D loss: 0.768507, acc.: 48.44%] [G loss: 0.931521]\n",
            "402 [D loss: 0.747372, acc.: 56.25%] [G loss: 0.996834]\n",
            "403 [D loss: 0.697410, acc.: 53.12%] [G loss: 1.294752]\n",
            "404 [D loss: 0.802826, acc.: 45.31%] [G loss: 0.996611]\n",
            "405 [D loss: 0.778278, acc.: 50.00%] [G loss: 0.989023]\n",
            "406 [D loss: 0.762058, acc.: 51.56%] [G loss: 1.079550]\n",
            "407 [D loss: 0.746549, acc.: 57.81%] [G loss: 0.974523]\n",
            "408 [D loss: 0.816395, acc.: 48.44%] [G loss: 0.990215]\n",
            "409 [D loss: 0.812207, acc.: 43.75%] [G loss: 0.800194]\n",
            "410 [D loss: 0.769601, acc.: 51.56%] [G loss: 0.895083]\n",
            "411 [D loss: 0.768619, acc.: 54.69%] [G loss: 1.199727]\n",
            "412 [D loss: 0.873854, acc.: 40.62%] [G loss: 1.054274]\n",
            "413 [D loss: 0.764555, acc.: 42.19%] [G loss: 1.094571]\n",
            "414 [D loss: 0.712871, acc.: 53.12%] [G loss: 1.183310]\n",
            "415 [D loss: 0.776924, acc.: 46.88%] [G loss: 1.026016]\n",
            "416 [D loss: 0.714832, acc.: 54.69%] [G loss: 1.163588]\n",
            "417 [D loss: 0.819494, acc.: 53.12%] [G loss: 1.060369]\n",
            "418 [D loss: 0.708158, acc.: 51.56%] [G loss: 1.059373]\n",
            "419 [D loss: 0.795853, acc.: 45.31%] [G loss: 0.963112]\n",
            "420 [D loss: 0.776171, acc.: 43.75%] [G loss: 0.903436]\n",
            "421 [D loss: 0.772101, acc.: 46.88%] [G loss: 0.982678]\n",
            "422 [D loss: 0.861682, acc.: 43.75%] [G loss: 0.906739]\n",
            "423 [D loss: 0.694155, acc.: 59.38%] [G loss: 0.984385]\n",
            "424 [D loss: 0.835622, acc.: 45.31%] [G loss: 1.145615]\n",
            "425 [D loss: 0.875094, acc.: 34.38%] [G loss: 1.025902]\n",
            "426 [D loss: 0.704415, acc.: 53.12%] [G loss: 0.956490]\n",
            "427 [D loss: 0.717813, acc.: 54.69%] [G loss: 0.976061]\n",
            "428 [D loss: 0.793440, acc.: 43.75%] [G loss: 0.969967]\n",
            "429 [D loss: 0.696571, acc.: 57.81%] [G loss: 0.963173]\n",
            "430 [D loss: 0.802187, acc.: 50.00%] [G loss: 0.907147]\n",
            "431 [D loss: 0.722849, acc.: 51.56%] [G loss: 0.982814]\n",
            "432 [D loss: 0.803088, acc.: 35.94%] [G loss: 1.081743]\n",
            "433 [D loss: 0.685811, acc.: 57.81%] [G loss: 0.995685]\n",
            "434 [D loss: 0.791309, acc.: 48.44%] [G loss: 0.822398]\n",
            "435 [D loss: 0.830778, acc.: 40.62%] [G loss: 0.929438]\n",
            "436 [D loss: 0.814779, acc.: 51.56%] [G loss: 1.072945]\n",
            "437 [D loss: 0.775394, acc.: 48.44%] [G loss: 1.180561]\n",
            "438 [D loss: 0.750556, acc.: 46.88%] [G loss: 1.080347]\n",
            "439 [D loss: 0.829898, acc.: 40.62%] [G loss: 1.077848]\n",
            "440 [D loss: 0.729241, acc.: 51.56%] [G loss: 1.030292]\n",
            "441 [D loss: 0.818082, acc.: 45.31%] [G loss: 0.987264]\n",
            "442 [D loss: 0.732475, acc.: 43.75%] [G loss: 0.909327]\n",
            "443 [D loss: 0.694881, acc.: 60.94%] [G loss: 1.073573]\n",
            "444 [D loss: 0.724227, acc.: 50.00%] [G loss: 1.029152]\n",
            "445 [D loss: 0.790730, acc.: 45.31%] [G loss: 0.932512]\n",
            "446 [D loss: 0.673741, acc.: 64.06%] [G loss: 0.951922]\n",
            "447 [D loss: 0.644264, acc.: 59.38%] [G loss: 1.109343]\n",
            "448 [D loss: 0.827010, acc.: 37.50%] [G loss: 0.959173]\n",
            "449 [D loss: 0.747525, acc.: 53.12%] [G loss: 1.121101]\n",
            "450 [D loss: 0.767901, acc.: 45.31%] [G loss: 0.814472]\n",
            "451 [D loss: 0.718221, acc.: 60.94%] [G loss: 0.927158]\n",
            "452 [D loss: 0.722976, acc.: 64.06%] [G loss: 1.023347]\n",
            "453 [D loss: 0.727385, acc.: 53.12%] [G loss: 1.082478]\n",
            "454 [D loss: 0.730723, acc.: 57.81%] [G loss: 0.898617]\n",
            "455 [D loss: 0.773738, acc.: 53.12%] [G loss: 0.921345]\n",
            "456 [D loss: 0.725092, acc.: 53.12%] [G loss: 1.223288]\n",
            "457 [D loss: 0.824886, acc.: 45.31%] [G loss: 1.056045]\n",
            "458 [D loss: 0.826436, acc.: 48.44%] [G loss: 0.979751]\n",
            "459 [D loss: 0.822509, acc.: 50.00%] [G loss: 0.887442]\n",
            "460 [D loss: 0.860005, acc.: 39.06%] [G loss: 1.090042]\n",
            "461 [D loss: 0.738009, acc.: 48.44%] [G loss: 1.143517]\n",
            "462 [D loss: 0.759655, acc.: 48.44%] [G loss: 1.133398]\n",
            "463 [D loss: 0.715890, acc.: 53.12%] [G loss: 1.068495]\n",
            "464 [D loss: 0.724319, acc.: 56.25%] [G loss: 1.047343]\n",
            "465 [D loss: 0.757461, acc.: 45.31%] [G loss: 1.061467]\n",
            "466 [D loss: 0.754347, acc.: 48.44%] [G loss: 1.151769]\n",
            "467 [D loss: 0.835790, acc.: 45.31%] [G loss: 0.980161]\n",
            "468 [D loss: 0.834706, acc.: 46.88%] [G loss: 1.119648]\n",
            "469 [D loss: 0.780475, acc.: 43.75%] [G loss: 0.982764]\n",
            "470 [D loss: 0.684651, acc.: 57.81%] [G loss: 0.903201]\n",
            "471 [D loss: 0.707216, acc.: 57.81%] [G loss: 0.997628]\n",
            "472 [D loss: 0.729606, acc.: 54.69%] [G loss: 0.949876]\n",
            "473 [D loss: 0.666747, acc.: 57.81%] [G loss: 1.172372]\n",
            "474 [D loss: 0.698558, acc.: 53.12%] [G loss: 1.248054]\n",
            "475 [D loss: 0.700979, acc.: 48.44%] [G loss: 0.962792]\n",
            "476 [D loss: 0.773787, acc.: 50.00%] [G loss: 1.034144]\n",
            "477 [D loss: 0.736895, acc.: 46.88%] [G loss: 0.951143]\n",
            "478 [D loss: 0.708907, acc.: 60.94%] [G loss: 1.015942]\n",
            "479 [D loss: 0.713387, acc.: 56.25%] [G loss: 0.890261]\n",
            "480 [D loss: 0.865245, acc.: 34.38%] [G loss: 0.983547]\n",
            "481 [D loss: 0.714381, acc.: 53.12%] [G loss: 1.122418]\n",
            "482 [D loss: 0.780432, acc.: 51.56%] [G loss: 0.863602]\n",
            "483 [D loss: 0.753285, acc.: 56.25%] [G loss: 0.974751]\n",
            "484 [D loss: 0.704728, acc.: 54.69%] [G loss: 1.082211]\n",
            "485 [D loss: 0.726668, acc.: 50.00%] [G loss: 0.889894]\n",
            "486 [D loss: 0.768532, acc.: 45.31%] [G loss: 0.974863]\n",
            "487 [D loss: 0.692325, acc.: 60.94%] [G loss: 1.160673]\n",
            "488 [D loss: 0.706190, acc.: 56.25%] [G loss: 0.959641]\n",
            "489 [D loss: 0.780973, acc.: 50.00%] [G loss: 1.066975]\n",
            "490 [D loss: 0.645171, acc.: 60.94%] [G loss: 1.067661]\n",
            "491 [D loss: 0.788627, acc.: 46.88%] [G loss: 1.164089]\n",
            "492 [D loss: 0.856318, acc.: 40.62%] [G loss: 1.142818]\n",
            "493 [D loss: 0.695398, acc.: 54.69%] [G loss: 1.110757]\n",
            "494 [D loss: 0.716928, acc.: 54.69%] [G loss: 1.066225]\n",
            "495 [D loss: 0.678837, acc.: 59.38%] [G loss: 0.885425]\n",
            "496 [D loss: 0.721039, acc.: 54.69%] [G loss: 1.017662]\n",
            "497 [D loss: 0.687156, acc.: 60.94%] [G loss: 0.856848]\n",
            "498 [D loss: 0.779471, acc.: 53.12%] [G loss: 0.874922]\n",
            "499 [D loss: 0.696771, acc.: 54.69%] [G loss: 1.196830]\n",
            "500 [D loss: 0.722177, acc.: 54.69%] [G loss: 1.004248]\n",
            "501 [D loss: 0.805054, acc.: 50.00%] [G loss: 0.905039]\n",
            "502 [D loss: 0.724581, acc.: 54.69%] [G loss: 0.961683]\n",
            "503 [D loss: 0.769725, acc.: 51.56%] [G loss: 1.000947]\n",
            "504 [D loss: 0.645983, acc.: 57.81%] [G loss: 1.118387]\n",
            "505 [D loss: 0.892277, acc.: 40.62%] [G loss: 0.918728]\n",
            "506 [D loss: 0.659982, acc.: 54.69%] [G loss: 1.048494]\n",
            "507 [D loss: 0.739584, acc.: 51.56%] [G loss: 1.061167]\n",
            "508 [D loss: 0.838090, acc.: 43.75%] [G loss: 0.876442]\n",
            "509 [D loss: 0.694178, acc.: 53.12%] [G loss: 0.950042]\n",
            "510 [D loss: 0.808702, acc.: 50.00%] [G loss: 1.090668]\n",
            "511 [D loss: 0.711694, acc.: 53.12%] [G loss: 0.919683]\n",
            "512 [D loss: 0.862182, acc.: 34.38%] [G loss: 0.950045]\n",
            "513 [D loss: 0.837742, acc.: 45.31%] [G loss: 0.984808]\n",
            "514 [D loss: 0.773302, acc.: 46.88%] [G loss: 1.054824]\n",
            "515 [D loss: 0.723111, acc.: 59.38%] [G loss: 1.009424]\n",
            "516 [D loss: 0.742089, acc.: 53.12%] [G loss: 1.088084]\n",
            "517 [D loss: 0.694155, acc.: 59.38%] [G loss: 1.005305]\n",
            "518 [D loss: 0.681187, acc.: 56.25%] [G loss: 0.996797]\n",
            "519 [D loss: 0.637089, acc.: 62.50%] [G loss: 0.891792]\n",
            "520 [D loss: 0.740518, acc.: 48.44%] [G loss: 1.123427]\n",
            "521 [D loss: 0.796240, acc.: 53.12%] [G loss: 0.927935]\n",
            "522 [D loss: 0.668492, acc.: 57.81%] [G loss: 1.070172]\n",
            "523 [D loss: 0.789979, acc.: 43.75%] [G loss: 1.055296]\n",
            "524 [D loss: 0.800914, acc.: 48.44%] [G loss: 1.122025]\n",
            "525 [D loss: 0.677386, acc.: 62.50%] [G loss: 0.958404]\n",
            "526 [D loss: 0.729559, acc.: 56.25%] [G loss: 1.062100]\n",
            "527 [D loss: 0.738731, acc.: 54.69%] [G loss: 0.932376]\n",
            "528 [D loss: 0.688186, acc.: 57.81%] [G loss: 0.969530]\n",
            "529 [D loss: 0.724602, acc.: 57.81%] [G loss: 1.087751]\n",
            "530 [D loss: 0.825486, acc.: 48.44%] [G loss: 1.234079]\n",
            "531 [D loss: 0.812973, acc.: 45.31%] [G loss: 1.211406]\n",
            "532 [D loss: 0.814702, acc.: 39.06%] [G loss: 1.051639]\n",
            "533 [D loss: 0.827116, acc.: 46.88%] [G loss: 1.024047]\n",
            "534 [D loss: 0.765754, acc.: 53.12%] [G loss: 0.993772]\n",
            "535 [D loss: 0.732594, acc.: 54.69%] [G loss: 1.026226]\n",
            "536 [D loss: 0.765269, acc.: 46.88%] [G loss: 0.828622]\n",
            "537 [D loss: 0.776209, acc.: 42.19%] [G loss: 1.002581]\n",
            "538 [D loss: 0.718802, acc.: 50.00%] [G loss: 1.061388]\n",
            "539 [D loss: 0.731102, acc.: 57.81%] [G loss: 1.057466]\n",
            "540 [D loss: 0.710085, acc.: 54.69%] [G loss: 0.985617]\n",
            "541 [D loss: 0.785801, acc.: 48.44%] [G loss: 0.965772]\n",
            "542 [D loss: 0.748535, acc.: 43.75%] [G loss: 1.069370]\n",
            "543 [D loss: 0.729402, acc.: 50.00%] [G loss: 0.863400]\n",
            "544 [D loss: 0.694687, acc.: 56.25%] [G loss: 1.101243]\n",
            "545 [D loss: 0.639607, acc.: 59.38%] [G loss: 1.099802]\n",
            "546 [D loss: 0.792997, acc.: 40.62%] [G loss: 0.882541]\n",
            "547 [D loss: 0.769192, acc.: 45.31%] [G loss: 1.028058]\n",
            "548 [D loss: 0.812366, acc.: 45.31%] [G loss: 1.044948]\n",
            "549 [D loss: 0.810372, acc.: 50.00%] [G loss: 0.985736]\n",
            "550 [D loss: 0.748672, acc.: 54.69%] [G loss: 1.028785]\n",
            "551 [D loss: 0.622379, acc.: 65.62%] [G loss: 0.993512]\n",
            "552 [D loss: 0.850893, acc.: 45.31%] [G loss: 1.165475]\n",
            "553 [D loss: 0.648742, acc.: 65.62%] [G loss: 1.047210]\n",
            "554 [D loss: 0.581180, acc.: 64.06%] [G loss: 1.132579]\n",
            "555 [D loss: 0.772705, acc.: 54.69%] [G loss: 0.908475]\n",
            "556 [D loss: 0.739554, acc.: 48.44%] [G loss: 1.107581]\n",
            "557 [D loss: 0.619802, acc.: 60.94%] [G loss: 1.141379]\n",
            "558 [D loss: 0.638098, acc.: 64.06%] [G loss: 1.015618]\n",
            "559 [D loss: 0.832469, acc.: 37.50%] [G loss: 1.045726]\n",
            "560 [D loss: 0.776761, acc.: 53.12%] [G loss: 1.019658]\n",
            "561 [D loss: 0.753030, acc.: 53.12%] [G loss: 1.030542]\n",
            "562 [D loss: 0.670072, acc.: 60.94%] [G loss: 0.996735]\n",
            "563 [D loss: 0.743981, acc.: 54.69%] [G loss: 1.000761]\n",
            "564 [D loss: 0.729479, acc.: 43.75%] [G loss: 1.090874]\n",
            "565 [D loss: 0.563337, acc.: 70.31%] [G loss: 1.069481]\n",
            "566 [D loss: 0.706836, acc.: 53.12%] [G loss: 0.992005]\n",
            "567 [D loss: 0.679932, acc.: 57.81%] [G loss: 1.021466]\n",
            "568 [D loss: 0.774982, acc.: 48.44%] [G loss: 1.185208]\n",
            "569 [D loss: 0.785403, acc.: 45.31%] [G loss: 0.984902]\n",
            "570 [D loss: 0.712609, acc.: 53.12%] [G loss: 0.939582]\n",
            "571 [D loss: 0.674616, acc.: 50.00%] [G loss: 1.004672]\n",
            "572 [D loss: 0.649838, acc.: 57.81%] [G loss: 1.181789]\n",
            "573 [D loss: 0.773343, acc.: 46.88%] [G loss: 1.023510]\n",
            "574 [D loss: 0.768126, acc.: 48.44%] [G loss: 1.077821]\n",
            "575 [D loss: 0.803207, acc.: 40.62%] [G loss: 1.076432]\n",
            "576 [D loss: 0.665175, acc.: 60.94%] [G loss: 1.052424]\n",
            "577 [D loss: 0.699458, acc.: 56.25%] [G loss: 1.083794]\n",
            "578 [D loss: 0.737405, acc.: 59.38%] [G loss: 0.946211]\n",
            "579 [D loss: 0.799345, acc.: 43.75%] [G loss: 0.927135]\n",
            "580 [D loss: 0.702275, acc.: 57.81%] [G loss: 1.077772]\n",
            "581 [D loss: 0.632023, acc.: 59.38%] [G loss: 1.034438]\n",
            "582 [D loss: 0.782850, acc.: 43.75%] [G loss: 0.950683]\n",
            "583 [D loss: 0.841415, acc.: 45.31%] [G loss: 1.046161]\n",
            "584 [D loss: 0.696555, acc.: 56.25%] [G loss: 0.858548]\n",
            "585 [D loss: 0.679496, acc.: 56.25%] [G loss: 0.920285]\n",
            "586 [D loss: 0.656379, acc.: 71.88%] [G loss: 1.064801]\n",
            "587 [D loss: 0.796008, acc.: 42.19%] [G loss: 1.114030]\n",
            "588 [D loss: 0.753894, acc.: 50.00%] [G loss: 1.002496]\n",
            "589 [D loss: 0.811226, acc.: 46.88%] [G loss: 1.013748]\n",
            "590 [D loss: 0.695159, acc.: 54.69%] [G loss: 0.944304]\n",
            "591 [D loss: 0.737410, acc.: 46.88%] [G loss: 1.035045]\n",
            "592 [D loss: 0.780502, acc.: 50.00%] [G loss: 1.011378]\n",
            "593 [D loss: 0.775667, acc.: 45.31%] [G loss: 1.065470]\n",
            "594 [D loss: 0.715055, acc.: 48.44%] [G loss: 0.927661]\n",
            "595 [D loss: 0.742098, acc.: 48.44%] [G loss: 1.046033]\n",
            "596 [D loss: 0.771294, acc.: 48.44%] [G loss: 1.130022]\n",
            "597 [D loss: 0.791067, acc.: 43.75%] [G loss: 1.107510]\n",
            "598 [D loss: 0.637275, acc.: 70.31%] [G loss: 1.246486]\n",
            "599 [D loss: 0.796065, acc.: 40.62%] [G loss: 1.200340]\n",
            "600 [D loss: 0.764884, acc.: 50.00%] [G loss: 1.022095]\n",
            "601 [D loss: 0.766273, acc.: 53.12%] [G loss: 1.042631]\n",
            "602 [D loss: 0.704305, acc.: 57.81%] [G loss: 1.079273]\n",
            "603 [D loss: 0.741145, acc.: 53.12%] [G loss: 0.983055]\n",
            "604 [D loss: 0.638231, acc.: 59.38%] [G loss: 0.978512]\n",
            "605 [D loss: 0.654118, acc.: 59.38%] [G loss: 0.988285]\n",
            "606 [D loss: 0.737996, acc.: 46.88%] [G loss: 1.095841]\n",
            "607 [D loss: 0.751927, acc.: 56.25%] [G loss: 1.223808]\n",
            "608 [D loss: 0.715624, acc.: 48.44%] [G loss: 1.045894]\n",
            "609 [D loss: 0.737102, acc.: 54.69%] [G loss: 1.073567]\n",
            "610 [D loss: 0.642112, acc.: 68.75%] [G loss: 1.034398]\n",
            "611 [D loss: 0.704899, acc.: 56.25%] [G loss: 1.069501]\n",
            "612 [D loss: 0.750287, acc.: 48.44%] [G loss: 0.991587]\n",
            "613 [D loss: 0.710443, acc.: 46.88%] [G loss: 1.035635]\n",
            "614 [D loss: 0.830649, acc.: 45.31%] [G loss: 0.934139]\n",
            "615 [D loss: 0.757380, acc.: 51.56%] [G loss: 0.987674]\n",
            "616 [D loss: 0.765944, acc.: 53.12%] [G loss: 1.079451]\n",
            "617 [D loss: 0.674396, acc.: 59.38%] [G loss: 1.140736]\n",
            "618 [D loss: 0.776794, acc.: 45.31%] [G loss: 0.959620]\n",
            "619 [D loss: 0.683380, acc.: 56.25%] [G loss: 1.033674]\n",
            "620 [D loss: 0.726002, acc.: 53.12%] [G loss: 0.863855]\n",
            "621 [D loss: 0.772097, acc.: 46.88%] [G loss: 1.137709]\n",
            "622 [D loss: 0.741193, acc.: 51.56%] [G loss: 0.933880]\n",
            "623 [D loss: 0.894783, acc.: 32.81%] [G loss: 0.958402]\n",
            "624 [D loss: 0.837773, acc.: 40.62%] [G loss: 0.952437]\n",
            "625 [D loss: 0.743810, acc.: 46.88%] [G loss: 1.019334]\n",
            "626 [D loss: 0.703971, acc.: 56.25%] [G loss: 1.024198]\n",
            "627 [D loss: 0.722167, acc.: 54.69%] [G loss: 0.989710]\n",
            "628 [D loss: 0.704603, acc.: 54.69%] [G loss: 0.982620]\n",
            "629 [D loss: 0.670141, acc.: 67.19%] [G loss: 1.012418]\n",
            "630 [D loss: 0.729017, acc.: 50.00%] [G loss: 1.168257]\n",
            "631 [D loss: 0.739110, acc.: 50.00%] [G loss: 1.041655]\n",
            "632 [D loss: 0.729790, acc.: 50.00%] [G loss: 0.954271]\n",
            "633 [D loss: 0.612034, acc.: 71.88%] [G loss: 1.147855]\n",
            "634 [D loss: 0.694329, acc.: 64.06%] [G loss: 0.954034]\n",
            "635 [D loss: 0.785410, acc.: 42.19%] [G loss: 0.923312]\n",
            "636 [D loss: 0.654601, acc.: 67.19%] [G loss: 0.914249]\n",
            "637 [D loss: 0.583141, acc.: 68.75%] [G loss: 1.081649]\n",
            "638 [D loss: 0.681684, acc.: 56.25%] [G loss: 1.076279]\n",
            "639 [D loss: 0.752962, acc.: 51.56%] [G loss: 1.273208]\n",
            "640 [D loss: 0.777778, acc.: 51.56%] [G loss: 0.897317]\n",
            "641 [D loss: 0.689134, acc.: 65.62%] [G loss: 1.097590]\n",
            "642 [D loss: 0.749993, acc.: 50.00%] [G loss: 1.066463]\n",
            "643 [D loss: 0.684564, acc.: 59.38%] [G loss: 1.036238]\n",
            "644 [D loss: 0.798889, acc.: 46.88%] [G loss: 0.997872]\n",
            "645 [D loss: 0.684544, acc.: 53.12%] [G loss: 0.971351]\n",
            "646 [D loss: 0.601088, acc.: 68.75%] [G loss: 0.971151]\n",
            "647 [D loss: 0.665102, acc.: 57.81%] [G loss: 1.163532]\n",
            "648 [D loss: 0.694423, acc.: 67.19%] [G loss: 1.102956]\n",
            "649 [D loss: 0.743138, acc.: 51.56%] [G loss: 1.062533]\n",
            "650 [D loss: 0.746758, acc.: 50.00%] [G loss: 1.093963]\n",
            "651 [D loss: 0.718443, acc.: 62.50%] [G loss: 1.131146]\n",
            "652 [D loss: 0.719562, acc.: 50.00%] [G loss: 1.033359]\n",
            "653 [D loss: 0.675998, acc.: 54.69%] [G loss: 1.075867]\n",
            "654 [D loss: 0.770179, acc.: 50.00%] [G loss: 1.071254]\n",
            "655 [D loss: 0.655948, acc.: 59.38%] [G loss: 1.013571]\n",
            "656 [D loss: 0.687833, acc.: 56.25%] [G loss: 1.003584]\n",
            "657 [D loss: 0.709816, acc.: 56.25%] [G loss: 0.867473]\n",
            "658 [D loss: 0.767403, acc.: 50.00%] [G loss: 0.855996]\n",
            "659 [D loss: 0.710942, acc.: 56.25%] [G loss: 1.150856]\n",
            "660 [D loss: 0.731538, acc.: 56.25%] [G loss: 0.959724]\n",
            "661 [D loss: 0.808919, acc.: 43.75%] [G loss: 0.882289]\n",
            "662 [D loss: 0.667793, acc.: 65.62%] [G loss: 1.102660]\n",
            "663 [D loss: 0.732136, acc.: 54.69%] [G loss: 1.093910]\n",
            "664 [D loss: 0.773076, acc.: 43.75%] [G loss: 0.952995]\n",
            "665 [D loss: 0.737911, acc.: 53.12%] [G loss: 0.921295]\n",
            "666 [D loss: 0.804538, acc.: 42.19%] [G loss: 0.950965]\n",
            "667 [D loss: 0.629908, acc.: 68.75%] [G loss: 1.011828]\n",
            "668 [D loss: 0.724508, acc.: 59.38%] [G loss: 0.878718]\n",
            "669 [D loss: 0.716018, acc.: 51.56%] [G loss: 1.132618]\n",
            "670 [D loss: 0.720266, acc.: 51.56%] [G loss: 0.980350]\n",
            "671 [D loss: 0.704106, acc.: 59.38%] [G loss: 0.896417]\n",
            "672 [D loss: 0.733695, acc.: 45.31%] [G loss: 0.931275]\n",
            "673 [D loss: 0.715475, acc.: 51.56%] [G loss: 1.132170]\n",
            "674 [D loss: 0.712865, acc.: 53.12%] [G loss: 1.108516]\n",
            "675 [D loss: 0.755492, acc.: 46.88%] [G loss: 1.219630]\n",
            "676 [D loss: 0.668749, acc.: 62.50%] [G loss: 1.126863]\n",
            "677 [D loss: 0.668631, acc.: 64.06%] [G loss: 0.954218]\n",
            "678 [D loss: 0.837978, acc.: 46.88%] [G loss: 0.910339]\n",
            "679 [D loss: 0.620532, acc.: 64.06%] [G loss: 1.094998]\n",
            "680 [D loss: 0.670023, acc.: 53.12%] [G loss: 1.197735]\n",
            "681 [D loss: 0.805277, acc.: 39.06%] [G loss: 0.928632]\n",
            "682 [D loss: 0.740665, acc.: 53.12%] [G loss: 1.016875]\n",
            "683 [D loss: 0.675426, acc.: 57.81%] [G loss: 1.103967]\n",
            "684 [D loss: 0.681645, acc.: 54.69%] [G loss: 1.002204]\n",
            "685 [D loss: 0.645113, acc.: 65.62%] [G loss: 1.125905]\n",
            "686 [D loss: 0.702324, acc.: 54.69%] [G loss: 1.098213]\n",
            "687 [D loss: 0.612444, acc.: 68.75%] [G loss: 1.118951]\n",
            "688 [D loss: 0.690161, acc.: 51.56%] [G loss: 0.993655]\n",
            "689 [D loss: 0.633198, acc.: 64.06%] [G loss: 1.010458]\n",
            "690 [D loss: 0.880843, acc.: 43.75%] [G loss: 0.866304]\n",
            "691 [D loss: 0.659823, acc.: 56.25%] [G loss: 0.914868]\n",
            "692 [D loss: 0.751975, acc.: 50.00%] [G loss: 1.021781]\n",
            "693 [D loss: 0.763816, acc.: 42.19%] [G loss: 0.887064]\n",
            "694 [D loss: 0.636675, acc.: 54.69%] [G loss: 1.164847]\n",
            "695 [D loss: 0.758129, acc.: 48.44%] [G loss: 1.066136]\n",
            "696 [D loss: 0.791760, acc.: 46.88%] [G loss: 1.148304]\n",
            "697 [D loss: 0.723133, acc.: 53.12%] [G loss: 0.864055]\n",
            "698 [D loss: 0.693761, acc.: 53.12%] [G loss: 1.029568]\n",
            "699 [D loss: 0.699157, acc.: 45.31%] [G loss: 0.984561]\n",
            "700 [D loss: 0.798137, acc.: 48.44%] [G loss: 0.996763]\n",
            "701 [D loss: 0.704504, acc.: 51.56%] [G loss: 0.988869]\n",
            "702 [D loss: 0.631170, acc.: 59.38%] [G loss: 1.161782]\n",
            "703 [D loss: 0.651203, acc.: 67.19%] [G loss: 1.146009]\n",
            "704 [D loss: 0.811842, acc.: 50.00%] [G loss: 0.920520]\n",
            "705 [D loss: 0.764185, acc.: 45.31%] [G loss: 0.922690]\n",
            "706 [D loss: 0.793490, acc.: 53.12%] [G loss: 0.920180]\n",
            "707 [D loss: 0.694478, acc.: 57.81%] [G loss: 1.169263]\n",
            "708 [D loss: 0.603099, acc.: 71.88%] [G loss: 1.047439]\n",
            "709 [D loss: 0.766535, acc.: 54.69%] [G loss: 0.998857]\n",
            "710 [D loss: 0.711435, acc.: 53.12%] [G loss: 1.015059]\n",
            "711 [D loss: 0.611280, acc.: 67.19%] [G loss: 1.176231]\n",
            "712 [D loss: 0.680760, acc.: 60.94%] [G loss: 0.969345]\n",
            "713 [D loss: 0.635015, acc.: 57.81%] [G loss: 0.984666]\n",
            "714 [D loss: 0.684359, acc.: 62.50%] [G loss: 1.136655]\n",
            "715 [D loss: 0.644214, acc.: 67.19%] [G loss: 1.122848]\n",
            "716 [D loss: 0.768459, acc.: 54.69%] [G loss: 1.142403]\n",
            "717 [D loss: 0.819392, acc.: 37.50%] [G loss: 1.028562]\n",
            "718 [D loss: 0.678356, acc.: 59.38%] [G loss: 0.988481]\n",
            "719 [D loss: 0.643659, acc.: 60.94%] [G loss: 0.951761]\n",
            "720 [D loss: 0.639895, acc.: 62.50%] [G loss: 1.105981]\n",
            "721 [D loss: 0.647497, acc.: 64.06%] [G loss: 1.066876]\n",
            "722 [D loss: 0.675875, acc.: 54.69%] [G loss: 1.155128]\n",
            "723 [D loss: 0.785974, acc.: 51.56%] [G loss: 0.969846]\n",
            "724 [D loss: 0.785999, acc.: 42.19%] [G loss: 1.074805]\n",
            "725 [D loss: 0.659037, acc.: 60.94%] [G loss: 1.244694]\n",
            "726 [D loss: 0.739168, acc.: 54.69%] [G loss: 1.221263]\n",
            "727 [D loss: 0.675087, acc.: 59.38%] [G loss: 1.003422]\n",
            "728 [D loss: 0.673060, acc.: 53.12%] [G loss: 1.049343]\n",
            "729 [D loss: 0.814135, acc.: 42.19%] [G loss: 1.194898]\n",
            "730 [D loss: 0.617052, acc.: 67.19%] [G loss: 1.036442]\n",
            "731 [D loss: 0.687673, acc.: 64.06%] [G loss: 0.980319]\n",
            "732 [D loss: 0.624243, acc.: 62.50%] [G loss: 1.049979]\n",
            "733 [D loss: 0.764866, acc.: 43.75%] [G loss: 1.051027]\n",
            "734 [D loss: 0.711091, acc.: 59.38%] [G loss: 0.996605]\n",
            "735 [D loss: 0.685618, acc.: 57.81%] [G loss: 0.911905]\n",
            "736 [D loss: 0.661980, acc.: 62.50%] [G loss: 0.895235]\n",
            "737 [D loss: 0.732516, acc.: 53.12%] [G loss: 1.019690]\n",
            "738 [D loss: 0.562417, acc.: 73.44%] [G loss: 1.201505]\n",
            "739 [D loss: 0.740462, acc.: 53.12%] [G loss: 1.092813]\n",
            "740 [D loss: 0.696658, acc.: 54.69%] [G loss: 1.196903]\n",
            "741 [D loss: 0.686108, acc.: 57.81%] [G loss: 1.066038]\n",
            "742 [D loss: 0.679842, acc.: 57.81%] [G loss: 1.067766]\n",
            "743 [D loss: 0.702220, acc.: 60.94%] [G loss: 1.210656]\n",
            "744 [D loss: 0.800371, acc.: 42.19%] [G loss: 0.929373]\n",
            "745 [D loss: 0.682171, acc.: 62.50%] [G loss: 0.997279]\n",
            "746 [D loss: 0.791478, acc.: 37.50%] [G loss: 0.996837]\n",
            "747 [D loss: 0.666570, acc.: 65.62%] [G loss: 1.053127]\n",
            "748 [D loss: 0.669117, acc.: 64.06%] [G loss: 1.008326]\n",
            "749 [D loss: 0.740432, acc.: 56.25%] [G loss: 0.887853]\n",
            "750 [D loss: 0.731121, acc.: 53.12%] [G loss: 0.965439]\n",
            "751 [D loss: 0.719058, acc.: 54.69%] [G loss: 1.116235]\n",
            "752 [D loss: 0.703376, acc.: 50.00%] [G loss: 0.916423]\n",
            "753 [D loss: 0.666778, acc.: 56.25%] [G loss: 1.052926]\n",
            "754 [D loss: 0.729001, acc.: 59.38%] [G loss: 1.019975]\n",
            "755 [D loss: 0.755277, acc.: 48.44%] [G loss: 1.092425]\n",
            "756 [D loss: 0.805863, acc.: 42.19%] [G loss: 0.896850]\n",
            "757 [D loss: 0.678344, acc.: 59.38%] [G loss: 1.018070]\n",
            "758 [D loss: 0.740075, acc.: 51.56%] [G loss: 0.986554]\n",
            "759 [D loss: 0.728972, acc.: 53.12%] [G loss: 1.099556]\n",
            "760 [D loss: 0.659459, acc.: 62.50%] [G loss: 1.072200]\n",
            "761 [D loss: 0.705858, acc.: 54.69%] [G loss: 1.026960]\n",
            "762 [D loss: 0.715716, acc.: 54.69%] [G loss: 1.029112]\n",
            "763 [D loss: 0.674671, acc.: 48.44%] [G loss: 1.014009]\n",
            "764 [D loss: 0.668347, acc.: 60.94%] [G loss: 0.970830]\n",
            "765 [D loss: 0.714462, acc.: 54.69%] [G loss: 1.006943]\n",
            "766 [D loss: 0.702236, acc.: 50.00%] [G loss: 0.923155]\n",
            "767 [D loss: 0.738233, acc.: 51.56%] [G loss: 0.805138]\n",
            "768 [D loss: 0.774097, acc.: 46.88%] [G loss: 1.072298]\n",
            "769 [D loss: 0.614950, acc.: 67.19%] [G loss: 1.162847]\n",
            "770 [D loss: 0.662448, acc.: 59.38%] [G loss: 1.177320]\n",
            "771 [D loss: 0.681159, acc.: 54.69%] [G loss: 1.038948]\n",
            "772 [D loss: 0.754557, acc.: 50.00%] [G loss: 0.996008]\n",
            "773 [D loss: 0.666129, acc.: 65.62%] [G loss: 1.130608]\n",
            "774 [D loss: 0.813910, acc.: 42.19%] [G loss: 0.795068]\n",
            "775 [D loss: 0.803353, acc.: 51.56%] [G loss: 1.155753]\n",
            "776 [D loss: 0.734113, acc.: 50.00%] [G loss: 0.997244]\n",
            "777 [D loss: 0.651420, acc.: 70.31%] [G loss: 1.039500]\n",
            "778 [D loss: 0.649557, acc.: 60.94%] [G loss: 1.028010]\n",
            "779 [D loss: 0.698375, acc.: 60.94%] [G loss: 1.241691]\n",
            "780 [D loss: 0.745037, acc.: 56.25%] [G loss: 1.027437]\n",
            "781 [D loss: 0.667637, acc.: 57.81%] [G loss: 0.974928]\n",
            "782 [D loss: 0.667510, acc.: 56.25%] [G loss: 1.206083]\n",
            "783 [D loss: 0.649210, acc.: 68.75%] [G loss: 1.148783]\n",
            "784 [D loss: 0.677245, acc.: 59.38%] [G loss: 1.112888]\n",
            "785 [D loss: 0.767489, acc.: 57.81%] [G loss: 0.972150]\n",
            "786 [D loss: 0.724936, acc.: 54.69%] [G loss: 1.135800]\n",
            "787 [D loss: 0.689478, acc.: 59.38%] [G loss: 1.064554]\n",
            "788 [D loss: 0.771912, acc.: 59.38%] [G loss: 0.822754]\n",
            "789 [D loss: 0.634520, acc.: 65.62%] [G loss: 1.045331]\n",
            "790 [D loss: 0.678146, acc.: 59.38%] [G loss: 1.037710]\n",
            "791 [D loss: 0.815792, acc.: 50.00%] [G loss: 0.891850]\n",
            "792 [D loss: 0.628404, acc.: 56.25%] [G loss: 1.098639]\n",
            "793 [D loss: 0.770673, acc.: 46.88%] [G loss: 0.973588]\n",
            "794 [D loss: 0.641662, acc.: 60.94%] [G loss: 0.994847]\n",
            "795 [D loss: 0.811375, acc.: 48.44%] [G loss: 0.942211]\n",
            "796 [D loss: 0.686120, acc.: 56.25%] [G loss: 1.078054]\n",
            "797 [D loss: 0.664674, acc.: 60.94%] [G loss: 1.068023]\n",
            "798 [D loss: 0.748035, acc.: 50.00%] [G loss: 1.046981]\n",
            "799 [D loss: 0.715501, acc.: 64.06%] [G loss: 1.129919]\n",
            "800 [D loss: 0.779076, acc.: 46.88%] [G loss: 0.914476]\n",
            "801 [D loss: 0.663025, acc.: 62.50%] [G loss: 1.156358]\n",
            "802 [D loss: 0.728363, acc.: 53.12%] [G loss: 1.070245]\n",
            "803 [D loss: 0.700106, acc.: 56.25%] [G loss: 0.985326]\n",
            "804 [D loss: 0.687610, acc.: 59.38%] [G loss: 0.987283]\n",
            "805 [D loss: 0.710217, acc.: 50.00%] [G loss: 1.069954]\n",
            "806 [D loss: 0.702684, acc.: 54.69%] [G loss: 0.908993]\n",
            "807 [D loss: 0.678731, acc.: 56.25%] [G loss: 1.183224]\n",
            "808 [D loss: 0.743770, acc.: 46.88%] [G loss: 1.073896]\n",
            "809 [D loss: 0.644534, acc.: 67.19%] [G loss: 1.054639]\n",
            "810 [D loss: 0.671623, acc.: 64.06%] [G loss: 1.329447]\n",
            "811 [D loss: 0.627208, acc.: 64.06%] [G loss: 0.993978]\n",
            "812 [D loss: 0.729845, acc.: 51.56%] [G loss: 1.187147]\n",
            "813 [D loss: 0.801792, acc.: 54.69%] [G loss: 1.133171]\n",
            "814 [D loss: 0.849361, acc.: 43.75%] [G loss: 0.882563]\n",
            "815 [D loss: 0.680909, acc.: 62.50%] [G loss: 0.937879]\n",
            "816 [D loss: 0.595762, acc.: 67.19%] [G loss: 1.244522]\n",
            "817 [D loss: 0.822821, acc.: 42.19%] [G loss: 1.067917]\n",
            "818 [D loss: 0.833181, acc.: 50.00%] [G loss: 1.137343]\n",
            "819 [D loss: 0.907885, acc.: 34.38%] [G loss: 0.972567]\n",
            "820 [D loss: 0.679093, acc.: 60.94%] [G loss: 1.012492]\n",
            "821 [D loss: 0.707156, acc.: 51.56%] [G loss: 0.991810]\n",
            "822 [D loss: 0.631701, acc.: 57.81%] [G loss: 1.053871]\n",
            "823 [D loss: 0.646683, acc.: 62.50%] [G loss: 1.078786]\n",
            "824 [D loss: 0.676915, acc.: 56.25%] [G loss: 0.912265]\n",
            "825 [D loss: 0.816986, acc.: 40.62%] [G loss: 0.939678]\n",
            "826 [D loss: 0.752437, acc.: 51.56%] [G loss: 1.018891]\n",
            "827 [D loss: 0.620345, acc.: 64.06%] [G loss: 1.005925]\n",
            "828 [D loss: 0.743950, acc.: 48.44%] [G loss: 1.038365]\n",
            "829 [D loss: 0.634033, acc.: 60.94%] [G loss: 1.048861]\n",
            "830 [D loss: 0.726432, acc.: 51.56%] [G loss: 1.065138]\n",
            "831 [D loss: 0.774881, acc.: 40.62%] [G loss: 1.028312]\n",
            "832 [D loss: 0.827291, acc.: 45.31%] [G loss: 1.139306]\n",
            "833 [D loss: 0.652463, acc.: 59.38%] [G loss: 1.125486]\n",
            "834 [D loss: 0.772493, acc.: 53.12%] [G loss: 0.997808]\n",
            "835 [D loss: 0.639311, acc.: 59.38%] [G loss: 0.922374]\n",
            "836 [D loss: 0.593749, acc.: 68.75%] [G loss: 1.131247]\n",
            "837 [D loss: 0.726884, acc.: 56.25%] [G loss: 1.013692]\n",
            "838 [D loss: 0.671692, acc.: 54.69%] [G loss: 0.947389]\n",
            "839 [D loss: 0.764434, acc.: 50.00%] [G loss: 0.967180]\n",
            "840 [D loss: 0.724369, acc.: 50.00%] [G loss: 1.113604]\n",
            "841 [D loss: 0.802834, acc.: 53.12%] [G loss: 0.904310]\n",
            "842 [D loss: 0.771387, acc.: 54.69%] [G loss: 1.112325]\n",
            "843 [D loss: 0.728648, acc.: 54.69%] [G loss: 1.022705]\n",
            "844 [D loss: 0.794352, acc.: 48.44%] [G loss: 1.169680]\n",
            "845 [D loss: 0.701893, acc.: 51.56%] [G loss: 0.910203]\n",
            "846 [D loss: 0.702442, acc.: 57.81%] [G loss: 1.015123]\n",
            "847 [D loss: 0.560432, acc.: 73.44%] [G loss: 0.960883]\n",
            "848 [D loss: 0.711985, acc.: 53.12%] [G loss: 1.000470]\n",
            "849 [D loss: 0.685282, acc.: 51.56%] [G loss: 0.939637]\n",
            "850 [D loss: 0.761362, acc.: 51.56%] [G loss: 1.050212]\n",
            "851 [D loss: 0.681549, acc.: 59.38%] [G loss: 1.134200]\n",
            "852 [D loss: 0.817191, acc.: 45.31%] [G loss: 1.020868]\n",
            "853 [D loss: 0.760450, acc.: 48.44%] [G loss: 0.871634]\n",
            "854 [D loss: 0.833507, acc.: 42.19%] [G loss: 1.102426]\n",
            "855 [D loss: 0.827984, acc.: 43.75%] [G loss: 1.041119]\n",
            "856 [D loss: 0.656319, acc.: 59.38%] [G loss: 1.147340]\n",
            "857 [D loss: 0.695809, acc.: 53.12%] [G loss: 0.956941]\n",
            "858 [D loss: 0.639346, acc.: 68.75%] [G loss: 1.080742]\n",
            "859 [D loss: 0.819497, acc.: 34.38%] [G loss: 1.059339]\n",
            "860 [D loss: 0.717371, acc.: 57.81%] [G loss: 0.997734]\n",
            "861 [D loss: 0.631191, acc.: 64.06%] [G loss: 0.920858]\n",
            "862 [D loss: 0.791800, acc.: 46.88%] [G loss: 1.003978]\n",
            "863 [D loss: 0.709396, acc.: 56.25%] [G loss: 0.901840]\n",
            "864 [D loss: 0.720630, acc.: 56.25%] [G loss: 0.832919]\n",
            "865 [D loss: 0.567978, acc.: 73.44%] [G loss: 0.902476]\n",
            "866 [D loss: 0.750323, acc.: 50.00%] [G loss: 0.902519]\n",
            "867 [D loss: 0.728107, acc.: 53.12%] [G loss: 0.951632]\n",
            "868 [D loss: 0.780656, acc.: 51.56%] [G loss: 0.876981]\n",
            "869 [D loss: 0.740194, acc.: 57.81%] [G loss: 1.088632]\n",
            "870 [D loss: 0.676753, acc.: 67.19%] [G loss: 1.136194]\n",
            "871 [D loss: 0.637733, acc.: 62.50%] [G loss: 1.128655]\n",
            "872 [D loss: 0.749101, acc.: 53.12%] [G loss: 1.057770]\n",
            "873 [D loss: 0.651081, acc.: 65.62%] [G loss: 1.010109]\n",
            "874 [D loss: 0.775510, acc.: 46.88%] [G loss: 0.968448]\n",
            "875 [D loss: 0.656618, acc.: 54.69%] [G loss: 1.024961]\n",
            "876 [D loss: 0.735159, acc.: 51.56%] [G loss: 1.089133]\n",
            "877 [D loss: 0.629240, acc.: 60.94%] [G loss: 1.050575]\n",
            "878 [D loss: 0.771933, acc.: 42.19%] [G loss: 1.022148]\n",
            "879 [D loss: 0.596630, acc.: 67.19%] [G loss: 1.206344]\n",
            "880 [D loss: 0.732116, acc.: 53.12%] [G loss: 1.037097]\n",
            "881 [D loss: 0.710927, acc.: 57.81%] [G loss: 1.201367]\n",
            "882 [D loss: 0.693778, acc.: 62.50%] [G loss: 0.859398]\n",
            "883 [D loss: 0.761562, acc.: 48.44%] [G loss: 0.902358]\n",
            "884 [D loss: 0.749433, acc.: 53.12%] [G loss: 0.979397]\n",
            "885 [D loss: 0.617161, acc.: 65.62%] [G loss: 1.002935]\n",
            "886 [D loss: 0.654815, acc.: 57.81%] [G loss: 0.986277]\n",
            "887 [D loss: 0.730582, acc.: 51.56%] [G loss: 1.039895]\n",
            "888 [D loss: 0.648053, acc.: 65.62%] [G loss: 0.973339]\n",
            "889 [D loss: 0.739924, acc.: 46.88%] [G loss: 0.930759]\n",
            "890 [D loss: 0.713328, acc.: 50.00%] [G loss: 1.092574]\n",
            "891 [D loss: 0.774309, acc.: 53.12%] [G loss: 0.870568]\n",
            "892 [D loss: 0.689223, acc.: 62.50%] [G loss: 1.102460]\n",
            "893 [D loss: 0.796908, acc.: 50.00%] [G loss: 0.989935]\n",
            "894 [D loss: 0.695122, acc.: 53.12%] [G loss: 0.958692]\n",
            "895 [D loss: 0.744283, acc.: 54.69%] [G loss: 1.231157]\n",
            "896 [D loss: 0.701418, acc.: 50.00%] [G loss: 1.076993]\n",
            "897 [D loss: 0.716523, acc.: 59.38%] [G loss: 0.941481]\n",
            "898 [D loss: 0.847152, acc.: 40.62%] [G loss: 0.994502]\n",
            "899 [D loss: 0.646331, acc.: 60.94%] [G loss: 0.985988]\n",
            "900 [D loss: 0.768159, acc.: 45.31%] [G loss: 1.019776]\n",
            "901 [D loss: 0.713897, acc.: 56.25%] [G loss: 1.195047]\n",
            "902 [D loss: 0.710021, acc.: 51.56%] [G loss: 1.188442]\n",
            "903 [D loss: 0.695407, acc.: 53.12%] [G loss: 1.055414]\n",
            "904 [D loss: 0.727340, acc.: 48.44%] [G loss: 0.855347]\n",
            "905 [D loss: 0.637705, acc.: 60.94%] [G loss: 1.058078]\n",
            "906 [D loss: 0.689561, acc.: 48.44%] [G loss: 1.127528]\n",
            "907 [D loss: 0.808831, acc.: 45.31%] [G loss: 0.999090]\n",
            "908 [D loss: 0.747788, acc.: 51.56%] [G loss: 1.067474]\n",
            "909 [D loss: 0.734589, acc.: 51.56%] [G loss: 1.062791]\n",
            "910 [D loss: 0.730193, acc.: 53.12%] [G loss: 0.982438]\n",
            "911 [D loss: 0.774202, acc.: 43.75%] [G loss: 0.826567]\n",
            "912 [D loss: 0.809029, acc.: 42.19%] [G loss: 1.027165]\n",
            "913 [D loss: 0.632548, acc.: 67.19%] [G loss: 0.872342]\n",
            "914 [D loss: 0.689828, acc.: 48.44%] [G loss: 1.034164]\n",
            "915 [D loss: 0.681564, acc.: 62.50%] [G loss: 1.069251]\n",
            "916 [D loss: 0.710065, acc.: 56.25%] [G loss: 1.090988]\n",
            "917 [D loss: 0.716270, acc.: 53.12%] [G loss: 1.140216]\n",
            "918 [D loss: 0.745235, acc.: 54.69%] [G loss: 1.171972]\n",
            "919 [D loss: 0.716781, acc.: 53.12%] [G loss: 0.855373]\n",
            "920 [D loss: 0.741499, acc.: 48.44%] [G loss: 0.920989]\n",
            "921 [D loss: 0.761916, acc.: 51.56%] [G loss: 0.996721]\n",
            "922 [D loss: 0.752616, acc.: 48.44%] [G loss: 1.014295]\n",
            "923 [D loss: 0.774340, acc.: 42.19%] [G loss: 1.069932]\n",
            "924 [D loss: 0.792334, acc.: 51.56%] [G loss: 0.934981]\n",
            "925 [D loss: 0.715650, acc.: 54.69%] [G loss: 1.081077]\n",
            "926 [D loss: 0.807468, acc.: 48.44%] [G loss: 1.072706]\n",
            "927 [D loss: 0.769361, acc.: 54.69%] [G loss: 0.972424]\n",
            "928 [D loss: 0.720397, acc.: 59.38%] [G loss: 0.924731]\n",
            "929 [D loss: 0.868462, acc.: 46.88%] [G loss: 0.935520]\n",
            "930 [D loss: 0.764650, acc.: 48.44%] [G loss: 1.047624]\n",
            "931 [D loss: 0.789177, acc.: 37.50%] [G loss: 0.825088]\n",
            "932 [D loss: 0.699680, acc.: 59.38%] [G loss: 1.052758]\n",
            "933 [D loss: 0.723854, acc.: 54.69%] [G loss: 0.991127]\n",
            "934 [D loss: 0.630593, acc.: 64.06%] [G loss: 0.974115]\n",
            "935 [D loss: 0.790823, acc.: 45.31%] [G loss: 0.923067]\n",
            "936 [D loss: 0.771619, acc.: 51.56%] [G loss: 1.052877]\n",
            "937 [D loss: 0.628834, acc.: 71.88%] [G loss: 1.135671]\n",
            "938 [D loss: 0.755182, acc.: 50.00%] [G loss: 1.023659]\n",
            "939 [D loss: 0.838225, acc.: 48.44%] [G loss: 0.974698]\n",
            "940 [D loss: 0.759723, acc.: 45.31%] [G loss: 0.854014]\n",
            "941 [D loss: 0.666197, acc.: 57.81%] [G loss: 1.060036]\n",
            "942 [D loss: 0.834795, acc.: 39.06%] [G loss: 0.831155]\n",
            "943 [D loss: 0.635299, acc.: 64.06%] [G loss: 1.112237]\n",
            "944 [D loss: 0.691716, acc.: 59.38%] [G loss: 1.100696]\n",
            "945 [D loss: 0.751222, acc.: 57.81%] [G loss: 0.982741]\n",
            "946 [D loss: 0.628604, acc.: 59.38%] [G loss: 1.004995]\n",
            "947 [D loss: 0.760812, acc.: 57.81%] [G loss: 0.944603]\n",
            "948 [D loss: 0.717598, acc.: 53.12%] [G loss: 0.974433]\n",
            "949 [D loss: 0.665521, acc.: 60.94%] [G loss: 0.958936]\n",
            "950 [D loss: 0.729889, acc.: 48.44%] [G loss: 1.018973]\n",
            "951 [D loss: 0.696351, acc.: 59.38%] [G loss: 0.798358]\n",
            "952 [D loss: 0.612282, acc.: 71.88%] [G loss: 1.104544]\n",
            "953 [D loss: 0.711552, acc.: 53.12%] [G loss: 0.932409]\n",
            "954 [D loss: 0.750383, acc.: 48.44%] [G loss: 1.020834]\n",
            "955 [D loss: 0.750669, acc.: 51.56%] [G loss: 1.155277]\n",
            "956 [D loss: 0.725717, acc.: 59.38%] [G loss: 1.034441]\n",
            "957 [D loss: 0.702897, acc.: 65.62%] [G loss: 1.115056]\n",
            "958 [D loss: 0.699226, acc.: 51.56%] [G loss: 0.885394]\n",
            "959 [D loss: 0.761995, acc.: 53.12%] [G loss: 0.955603]\n",
            "960 [D loss: 0.732721, acc.: 53.12%] [G loss: 0.940614]\n",
            "961 [D loss: 0.727624, acc.: 51.56%] [G loss: 0.964101]\n",
            "962 [D loss: 0.688808, acc.: 59.38%] [G loss: 1.134956]\n",
            "963 [D loss: 0.689086, acc.: 53.12%] [G loss: 1.015105]\n",
            "964 [D loss: 0.701122, acc.: 59.38%] [G loss: 0.987775]\n",
            "965 [D loss: 0.736212, acc.: 56.25%] [G loss: 1.064289]\n",
            "966 [D loss: 0.641877, acc.: 64.06%] [G loss: 1.073257]\n",
            "967 [D loss: 0.775132, acc.: 57.81%] [G loss: 1.083327]\n",
            "968 [D loss: 0.667905, acc.: 54.69%] [G loss: 1.131744]\n",
            "969 [D loss: 0.624519, acc.: 62.50%] [G loss: 1.165675]\n",
            "970 [D loss: 0.880475, acc.: 32.81%] [G loss: 0.903860]\n",
            "971 [D loss: 0.785161, acc.: 50.00%] [G loss: 0.897143]\n",
            "972 [D loss: 0.772628, acc.: 46.88%] [G loss: 0.958930]\n",
            "973 [D loss: 0.800761, acc.: 48.44%] [G loss: 0.907362]\n",
            "974 [D loss: 0.859705, acc.: 35.94%] [G loss: 1.077175]\n",
            "975 [D loss: 0.758134, acc.: 43.75%] [G loss: 1.035630]\n",
            "976 [D loss: 0.822708, acc.: 45.31%] [G loss: 0.930245]\n",
            "977 [D loss: 0.826289, acc.: 37.50%] [G loss: 0.951872]\n",
            "978 [D loss: 0.721257, acc.: 57.81%] [G loss: 1.120646]\n",
            "979 [D loss: 0.668154, acc.: 62.50%] [G loss: 1.077247]\n",
            "980 [D loss: 0.784236, acc.: 46.88%] [G loss: 1.022146]\n",
            "981 [D loss: 0.755888, acc.: 53.12%] [G loss: 1.011205]\n",
            "982 [D loss: 0.689697, acc.: 56.25%] [G loss: 0.984713]\n",
            "983 [D loss: 0.731315, acc.: 51.56%] [G loss: 0.897008]\n",
            "984 [D loss: 0.666811, acc.: 62.50%] [G loss: 1.085092]\n",
            "985 [D loss: 0.759735, acc.: 54.69%] [G loss: 1.030792]\n",
            "986 [D loss: 0.884585, acc.: 37.50%] [G loss: 0.884507]\n",
            "987 [D loss: 0.622070, acc.: 70.31%] [G loss: 1.178015]\n",
            "988 [D loss: 0.678009, acc.: 59.38%] [G loss: 0.990026]\n",
            "989 [D loss: 0.638651, acc.: 62.50%] [G loss: 1.136999]\n",
            "990 [D loss: 0.712243, acc.: 53.12%] [G loss: 1.031434]\n",
            "991 [D loss: 0.874437, acc.: 39.06%] [G loss: 0.974993]\n",
            "992 [D loss: 0.841709, acc.: 37.50%] [G loss: 0.837422]\n",
            "993 [D loss: 0.659347, acc.: 60.94%] [G loss: 1.136044]\n",
            "994 [D loss: 0.646342, acc.: 67.19%] [G loss: 1.039012]\n",
            "995 [D loss: 0.705445, acc.: 51.56%] [G loss: 1.029063]\n",
            "996 [D loss: 0.688257, acc.: 60.94%] [G loss: 0.911244]\n",
            "997 [D loss: 0.742743, acc.: 48.44%] [G loss: 0.994734]\n",
            "998 [D loss: 0.742890, acc.: 51.56%] [G loss: 0.999252]\n",
            "999 [D loss: 0.717099, acc.: 57.81%] [G loss: 1.002666]\n",
            "1000 [D loss: 0.696216, acc.: 56.25%] [G loss: 1.019262]\n",
            "1001 [D loss: 0.688085, acc.: 53.12%] [G loss: 0.873943]\n",
            "1002 [D loss: 0.841221, acc.: 46.88%] [G loss: 0.945785]\n",
            "1003 [D loss: 0.725822, acc.: 51.56%] [G loss: 1.014892]\n",
            "1004 [D loss: 0.728098, acc.: 45.31%] [G loss: 0.921387]\n",
            "1005 [D loss: 0.757005, acc.: 45.31%] [G loss: 0.748517]\n",
            "1006 [D loss: 0.794167, acc.: 50.00%] [G loss: 1.050433]\n",
            "1007 [D loss: 0.684504, acc.: 53.12%] [G loss: 1.136129]\n",
            "1008 [D loss: 0.731045, acc.: 40.62%] [G loss: 0.908391]\n",
            "1009 [D loss: 0.676338, acc.: 54.69%] [G loss: 1.040350]\n",
            "1010 [D loss: 0.765803, acc.: 53.12%] [G loss: 1.148598]\n",
            "1011 [D loss: 0.751495, acc.: 46.88%] [G loss: 1.063444]\n",
            "1012 [D loss: 0.649612, acc.: 70.31%] [G loss: 0.881855]\n",
            "1013 [D loss: 0.722591, acc.: 46.88%] [G loss: 1.134810]\n",
            "1014 [D loss: 0.882108, acc.: 42.19%] [G loss: 0.925946]\n",
            "1015 [D loss: 0.782662, acc.: 40.62%] [G loss: 0.793019]\n",
            "1016 [D loss: 0.682543, acc.: 59.38%] [G loss: 0.881094]\n",
            "1017 [D loss: 0.678027, acc.: 67.19%] [G loss: 0.919461]\n",
            "1018 [D loss: 0.764489, acc.: 45.31%] [G loss: 1.068015]\n",
            "1019 [D loss: 0.708485, acc.: 53.12%] [G loss: 0.950292]\n",
            "1020 [D loss: 0.712815, acc.: 45.31%] [G loss: 1.074535]\n",
            "1021 [D loss: 0.824848, acc.: 45.31%] [G loss: 1.155310]\n",
            "1022 [D loss: 0.902609, acc.: 29.69%] [G loss: 0.901347]\n",
            "1023 [D loss: 0.782034, acc.: 50.00%] [G loss: 1.083879]\n",
            "1024 [D loss: 0.731023, acc.: 54.69%] [G loss: 0.922846]\n",
            "1025 [D loss: 0.615923, acc.: 71.88%] [G loss: 0.902913]\n",
            "1026 [D loss: 0.722519, acc.: 54.69%] [G loss: 0.950793]\n",
            "1027 [D loss: 0.772646, acc.: 43.75%] [G loss: 0.914861]\n",
            "1028 [D loss: 0.754349, acc.: 51.56%] [G loss: 0.974486]\n",
            "1029 [D loss: 0.720470, acc.: 57.81%] [G loss: 0.905235]\n",
            "1030 [D loss: 0.706526, acc.: 51.56%] [G loss: 0.898194]\n",
            "1031 [D loss: 0.754656, acc.: 46.88%] [G loss: 0.919180]\n",
            "1032 [D loss: 0.688515, acc.: 60.94%] [G loss: 0.876749]\n",
            "1033 [D loss: 0.747814, acc.: 53.12%] [G loss: 1.177199]\n",
            "1034 [D loss: 0.762759, acc.: 46.88%] [G loss: 0.931629]\n",
            "1035 [D loss: 0.761431, acc.: 53.12%] [G loss: 0.920599]\n",
            "1036 [D loss: 0.777753, acc.: 56.25%] [G loss: 0.998867]\n",
            "1037 [D loss: 0.745673, acc.: 46.88%] [G loss: 0.892875]\n",
            "1038 [D loss: 0.763667, acc.: 43.75%] [G loss: 0.961411]\n",
            "1039 [D loss: 0.673998, acc.: 57.81%] [G loss: 0.970819]\n",
            "1040 [D loss: 0.785607, acc.: 46.88%] [G loss: 1.029389]\n",
            "1041 [D loss: 0.751476, acc.: 54.69%] [G loss: 1.000549]\n",
            "1042 [D loss: 0.744874, acc.: 50.00%] [G loss: 1.170509]\n",
            "1043 [D loss: 0.625511, acc.: 67.19%] [G loss: 1.075172]\n",
            "1044 [D loss: 0.822743, acc.: 40.62%] [G loss: 0.865367]\n",
            "1045 [D loss: 0.699171, acc.: 51.56%] [G loss: 1.046224]\n",
            "1046 [D loss: 0.702193, acc.: 59.38%] [G loss: 0.977223]\n",
            "1047 [D loss: 0.747150, acc.: 48.44%] [G loss: 0.902608]\n",
            "1048 [D loss: 0.772008, acc.: 46.88%] [G loss: 0.979662]\n",
            "1049 [D loss: 0.681523, acc.: 57.81%] [G loss: 1.168776]\n",
            "1050 [D loss: 0.645927, acc.: 64.06%] [G loss: 0.940536]\n",
            "1051 [D loss: 0.763394, acc.: 50.00%] [G loss: 0.995260]\n",
            "1052 [D loss: 0.768139, acc.: 45.31%] [G loss: 0.929916]\n",
            "1053 [D loss: 0.771107, acc.: 54.69%] [G loss: 1.028322]\n",
            "1054 [D loss: 0.643248, acc.: 64.06%] [G loss: 0.979471]\n",
            "1055 [D loss: 0.692449, acc.: 54.69%] [G loss: 0.979661]\n",
            "1056 [D loss: 0.764664, acc.: 43.75%] [G loss: 1.005506]\n",
            "1057 [D loss: 0.722450, acc.: 42.19%] [G loss: 1.034312]\n",
            "1058 [D loss: 0.729491, acc.: 51.56%] [G loss: 0.963404]\n",
            "1059 [D loss: 0.634051, acc.: 65.62%] [G loss: 1.021310]\n",
            "1060 [D loss: 0.641358, acc.: 64.06%] [G loss: 0.946023]\n",
            "1061 [D loss: 0.697266, acc.: 46.88%] [G loss: 1.012701]\n",
            "1062 [D loss: 0.782313, acc.: 48.44%] [G loss: 0.922349]\n",
            "1063 [D loss: 0.681871, acc.: 57.81%] [G loss: 1.086780]\n",
            "1064 [D loss: 0.780513, acc.: 48.44%] [G loss: 0.879053]\n",
            "1065 [D loss: 0.732022, acc.: 48.44%] [G loss: 1.116668]\n",
            "1066 [D loss: 0.770292, acc.: 54.69%] [G loss: 0.902446]\n",
            "1067 [D loss: 0.700350, acc.: 59.38%] [G loss: 0.976564]\n",
            "1068 [D loss: 0.678623, acc.: 56.25%] [G loss: 0.890359]\n",
            "1069 [D loss: 0.785359, acc.: 43.75%] [G loss: 0.880865]\n",
            "1070 [D loss: 0.732189, acc.: 50.00%] [G loss: 1.031883]\n",
            "1071 [D loss: 0.741224, acc.: 50.00%] [G loss: 0.838656]\n",
            "1072 [D loss: 0.769445, acc.: 43.75%] [G loss: 0.889105]\n",
            "1073 [D loss: 0.805386, acc.: 39.06%] [G loss: 1.020949]\n",
            "1074 [D loss: 0.787943, acc.: 51.56%] [G loss: 0.833742]\n",
            "1075 [D loss: 0.850937, acc.: 28.12%] [G loss: 0.952257]\n",
            "1076 [D loss: 0.723871, acc.: 57.81%] [G loss: 1.015050]\n",
            "1077 [D loss: 0.743880, acc.: 45.31%] [G loss: 1.017344]\n",
            "1078 [D loss: 0.716195, acc.: 50.00%] [G loss: 0.990938]\n",
            "1079 [D loss: 0.754983, acc.: 51.56%] [G loss: 0.980269]\n",
            "1080 [D loss: 0.710592, acc.: 56.25%] [G loss: 0.951264]\n",
            "1081 [D loss: 0.803542, acc.: 46.88%] [G loss: 0.964191]\n",
            "1082 [D loss: 0.712706, acc.: 54.69%] [G loss: 0.910787]\n",
            "1083 [D loss: 0.692718, acc.: 62.50%] [G loss: 1.001847]\n",
            "1084 [D loss: 0.792634, acc.: 42.19%] [G loss: 1.064504]\n",
            "1085 [D loss: 0.650292, acc.: 62.50%] [G loss: 0.994152]\n",
            "1086 [D loss: 0.784782, acc.: 45.31%] [G loss: 0.954198]\n",
            "1087 [D loss: 0.695632, acc.: 53.12%] [G loss: 1.086920]\n",
            "1088 [D loss: 0.749658, acc.: 56.25%] [G loss: 0.980083]\n",
            "1089 [D loss: 0.756342, acc.: 51.56%] [G loss: 1.014476]\n",
            "1090 [D loss: 0.743445, acc.: 46.88%] [G loss: 1.054034]\n",
            "1091 [D loss: 0.746770, acc.: 51.56%] [G loss: 0.797717]\n",
            "1092 [D loss: 0.715949, acc.: 56.25%] [G loss: 0.873258]\n",
            "1093 [D loss: 0.685683, acc.: 54.69%] [G loss: 0.990771]\n",
            "1094 [D loss: 0.766335, acc.: 51.56%] [G loss: 0.833246]\n",
            "1095 [D loss: 0.729388, acc.: 46.88%] [G loss: 1.012124]\n",
            "1096 [D loss: 0.786809, acc.: 46.88%] [G loss: 0.958150]\n",
            "1097 [D loss: 0.779705, acc.: 45.31%] [G loss: 1.016157]\n",
            "1098 [D loss: 0.686618, acc.: 60.94%] [G loss: 1.016165]\n",
            "1099 [D loss: 0.689550, acc.: 67.19%] [G loss: 0.859683]\n",
            "1100 [D loss: 0.698070, acc.: 53.12%] [G loss: 0.784613]\n",
            "1101 [D loss: 0.731739, acc.: 51.56%] [G loss: 1.094775]\n",
            "1102 [D loss: 0.728804, acc.: 54.69%] [G loss: 1.067544]\n",
            "1103 [D loss: 0.783372, acc.: 50.00%] [G loss: 1.072032]\n",
            "1104 [D loss: 0.702656, acc.: 53.12%] [G loss: 0.967891]\n",
            "1105 [D loss: 0.716103, acc.: 56.25%] [G loss: 1.098911]\n",
            "1106 [D loss: 0.724849, acc.: 46.88%] [G loss: 1.114128]\n",
            "1107 [D loss: 0.715396, acc.: 53.12%] [G loss: 0.939600]\n",
            "1108 [D loss: 0.873860, acc.: 42.19%] [G loss: 0.842656]\n",
            "1109 [D loss: 0.726683, acc.: 53.12%] [G loss: 0.994274]\n",
            "1110 [D loss: 0.653543, acc.: 57.81%] [G loss: 1.023236]\n",
            "1111 [D loss: 0.728690, acc.: 53.12%] [G loss: 0.949987]\n",
            "1112 [D loss: 0.826247, acc.: 51.56%] [G loss: 0.820500]\n",
            "1113 [D loss: 0.627209, acc.: 64.06%] [G loss: 0.963888]\n",
            "1114 [D loss: 0.717762, acc.: 56.25%] [G loss: 0.948707]\n",
            "1115 [D loss: 0.635140, acc.: 62.50%] [G loss: 0.908029]\n",
            "1116 [D loss: 0.681720, acc.: 60.94%] [G loss: 1.080882]\n",
            "1117 [D loss: 0.713645, acc.: 51.56%] [G loss: 1.031215]\n",
            "1118 [D loss: 0.701061, acc.: 56.25%] [G loss: 0.939211]\n",
            "1119 [D loss: 0.741248, acc.: 54.69%] [G loss: 0.943300]\n",
            "1120 [D loss: 0.618599, acc.: 60.94%] [G loss: 0.948619]\n",
            "1121 [D loss: 0.759220, acc.: 46.88%] [G loss: 1.013431]\n",
            "1122 [D loss: 0.677116, acc.: 56.25%] [G loss: 0.946605]\n",
            "1123 [D loss: 0.696271, acc.: 57.81%] [G loss: 1.113038]\n",
            "1124 [D loss: 0.644600, acc.: 57.81%] [G loss: 1.083417]\n",
            "1125 [D loss: 0.745999, acc.: 45.31%] [G loss: 1.097471]\n",
            "1126 [D loss: 0.751904, acc.: 53.12%] [G loss: 1.044864]\n",
            "1127 [D loss: 0.786369, acc.: 45.31%] [G loss: 1.102653]\n",
            "1128 [D loss: 0.694440, acc.: 54.69%] [G loss: 0.971306]\n",
            "1129 [D loss: 0.696412, acc.: 54.69%] [G loss: 0.901144]\n",
            "1130 [D loss: 0.756155, acc.: 46.88%] [G loss: 1.067806]\n",
            "1131 [D loss: 0.665447, acc.: 53.12%] [G loss: 0.966915]\n",
            "1132 [D loss: 0.743014, acc.: 50.00%] [G loss: 1.021377]\n",
            "1133 [D loss: 0.740321, acc.: 59.38%] [G loss: 0.934562]\n",
            "1134 [D loss: 0.636147, acc.: 54.69%] [G loss: 1.037933]\n",
            "1135 [D loss: 0.683161, acc.: 62.50%] [G loss: 0.958096]\n",
            "1136 [D loss: 0.802881, acc.: 46.88%] [G loss: 0.817651]\n",
            "1137 [D loss: 0.757394, acc.: 53.12%] [G loss: 1.081998]\n",
            "1138 [D loss: 0.746276, acc.: 51.56%] [G loss: 0.983743]\n",
            "1139 [D loss: 0.759133, acc.: 50.00%] [G loss: 1.031240]\n",
            "1140 [D loss: 0.764964, acc.: 46.88%] [G loss: 1.077634]\n",
            "1141 [D loss: 0.671238, acc.: 59.38%] [G loss: 1.065323]\n",
            "1142 [D loss: 0.778917, acc.: 42.19%] [G loss: 0.968998]\n",
            "1143 [D loss: 0.828918, acc.: 42.19%] [G loss: 1.038850]\n",
            "1144 [D loss: 0.697437, acc.: 56.25%] [G loss: 1.027841]\n",
            "1145 [D loss: 0.721849, acc.: 56.25%] [G loss: 1.109674]\n",
            "1146 [D loss: 0.669352, acc.: 56.25%] [G loss: 1.056575]\n",
            "1147 [D loss: 0.748273, acc.: 53.12%] [G loss: 0.854414]\n",
            "1148 [D loss: 0.708227, acc.: 57.81%] [G loss: 1.000098]\n",
            "1149 [D loss: 0.756757, acc.: 46.88%] [G loss: 0.929716]\n",
            "1150 [D loss: 0.868361, acc.: 40.62%] [G loss: 0.850264]\n",
            "1151 [D loss: 0.741450, acc.: 53.12%] [G loss: 0.889412]\n",
            "1152 [D loss: 0.790329, acc.: 37.50%] [G loss: 0.945384]\n",
            "1153 [D loss: 0.731610, acc.: 59.38%] [G loss: 0.934017]\n",
            "1154 [D loss: 0.656849, acc.: 56.25%] [G loss: 0.886870]\n",
            "1155 [D loss: 0.723947, acc.: 54.69%] [G loss: 1.082985]\n",
            "1156 [D loss: 0.690466, acc.: 59.38%] [G loss: 0.860736]\n",
            "1157 [D loss: 0.736511, acc.: 51.56%] [G loss: 1.049220]\n",
            "1158 [D loss: 0.676515, acc.: 60.94%] [G loss: 1.100461]\n",
            "1159 [D loss: 0.764604, acc.: 50.00%] [G loss: 0.982273]\n",
            "1160 [D loss: 0.761585, acc.: 46.88%] [G loss: 1.054589]\n",
            "1161 [D loss: 0.791913, acc.: 48.44%] [G loss: 1.030720]\n",
            "1162 [D loss: 0.703932, acc.: 50.00%] [G loss: 1.023523]\n",
            "1163 [D loss: 0.689178, acc.: 60.94%] [G loss: 1.029702]\n",
            "1164 [D loss: 0.778710, acc.: 43.75%] [G loss: 0.986185]\n",
            "1165 [D loss: 0.685931, acc.: 64.06%] [G loss: 0.982464]\n",
            "1166 [D loss: 0.720517, acc.: 56.25%] [G loss: 1.025002]\n",
            "1167 [D loss: 0.796677, acc.: 46.88%] [G loss: 0.938299]\n",
            "1168 [D loss: 0.699212, acc.: 62.50%] [G loss: 0.865599]\n",
            "1169 [D loss: 0.657798, acc.: 60.94%] [G loss: 0.988476]\n",
            "1170 [D loss: 0.812723, acc.: 39.06%] [G loss: 0.973607]\n",
            "1171 [D loss: 0.718389, acc.: 51.56%] [G loss: 1.104213]\n",
            "1172 [D loss: 0.608588, acc.: 70.31%] [G loss: 0.935783]\n",
            "1173 [D loss: 0.730522, acc.: 57.81%] [G loss: 0.924168]\n",
            "1174 [D loss: 0.652645, acc.: 57.81%] [G loss: 1.039577]\n",
            "1175 [D loss: 0.716932, acc.: 54.69%] [G loss: 0.846549]\n",
            "1176 [D loss: 0.632132, acc.: 65.62%] [G loss: 1.026353]\n",
            "1177 [D loss: 0.756060, acc.: 50.00%] [G loss: 0.954057]\n",
            "1178 [D loss: 0.743827, acc.: 50.00%] [G loss: 1.093181]\n",
            "1179 [D loss: 0.688293, acc.: 60.94%] [G loss: 0.934778]\n",
            "1180 [D loss: 0.743159, acc.: 53.12%] [G loss: 0.972957]\n",
            "1181 [D loss: 0.757408, acc.: 46.88%] [G loss: 0.975426]\n",
            "1182 [D loss: 0.739737, acc.: 53.12%] [G loss: 0.910844]\n",
            "1183 [D loss: 0.642933, acc.: 60.94%] [G loss: 1.061246]\n",
            "1184 [D loss: 0.905462, acc.: 35.94%] [G loss: 0.857481]\n",
            "1185 [D loss: 0.725657, acc.: 48.44%] [G loss: 1.104288]\n",
            "1186 [D loss: 0.745287, acc.: 40.62%] [G loss: 0.964350]\n",
            "1187 [D loss: 0.803979, acc.: 40.62%] [G loss: 1.061695]\n",
            "1188 [D loss: 0.650434, acc.: 56.25%] [G loss: 1.101923]\n",
            "1189 [D loss: 0.694166, acc.: 57.81%] [G loss: 0.987869]\n",
            "1190 [D loss: 0.758578, acc.: 56.25%] [G loss: 0.974850]\n",
            "1191 [D loss: 0.656228, acc.: 60.94%] [G loss: 0.996121]\n",
            "1192 [D loss: 0.716399, acc.: 45.31%] [G loss: 1.028147]\n",
            "1193 [D loss: 0.813880, acc.: 43.75%] [G loss: 1.062039]\n",
            "1194 [D loss: 0.742351, acc.: 54.69%] [G loss: 1.036574]\n",
            "1195 [D loss: 0.805257, acc.: 42.19%] [G loss: 0.968530]\n",
            "1196 [D loss: 0.703204, acc.: 48.44%] [G loss: 1.008486]\n",
            "1197 [D loss: 0.607994, acc.: 70.31%] [G loss: 0.804698]\n",
            "1198 [D loss: 0.723639, acc.: 50.00%] [G loss: 1.000521]\n",
            "1199 [D loss: 0.666593, acc.: 54.69%] [G loss: 1.005873]\n",
            "1200 [D loss: 0.709348, acc.: 46.88%] [G loss: 0.859890]\n",
            "1201 [D loss: 0.724119, acc.: 43.75%] [G loss: 0.836634]\n",
            "1202 [D loss: 0.782744, acc.: 43.75%] [G loss: 0.885937]\n",
            "1203 [D loss: 0.637615, acc.: 54.69%] [G loss: 0.884687]\n",
            "1204 [D loss: 0.775250, acc.: 46.88%] [G loss: 0.854621]\n",
            "1205 [D loss: 0.761550, acc.: 48.44%] [G loss: 0.958107]\n",
            "1206 [D loss: 0.791678, acc.: 43.75%] [G loss: 0.905730]\n",
            "1207 [D loss: 0.825492, acc.: 45.31%] [G loss: 0.948770]\n",
            "1208 [D loss: 0.719934, acc.: 56.25%] [G loss: 0.988953]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mDeV5TQZKcv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}